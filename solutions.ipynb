{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from heapq import heappop, heappush\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Direction(Enum):\n",
    "    UP = 0\n",
    "    RIGHT = 1\n",
    "    DOWN = 2\n",
    "    LEFT = 3\n",
    "\n",
    "\n",
    "def rotate_right(direction):\n",
    "    return Direction((direction.value + 1) % 4)\n",
    "\n",
    "\n",
    "def rotate_left(direction):\n",
    "    return Direction((direction.value - 1) % 4)\n",
    "\n",
    "\n",
    "def is_opposite(d1, d2):\n",
    "    return rotate_right(rotate_right(d1)) == d2\n",
    "\n",
    "\n",
    "def get_direction(symbol):\n",
    "    return Direction(\"^>v<\".index(symbol.lower()))\n",
    "\n",
    "\n",
    "dx_vectors = np.array(\n",
    "    [\n",
    "        [-1, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [0, -1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_dx(direction):\n",
    "    return dx_vectors[direction.value]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2000468)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"inputs/1.txt\", dtype=int)\n",
    "sorted_data = np.sort(data, axis=0)\n",
    "np.abs(sorted_data[:, 0] - sorted_data[:, 1]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18567089.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.concat(\n",
    "    [\n",
    "        pd.Series(sorted_data[:, 0]).value_counts().rename(\"0\"),\n",
    "        pd.Series(sorted_data[:, 1]).value_counts().rename(\"1\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").dropna()\n",
    "\n",
    "(counts.iloc[:, 0] * counts.iloc[:, 1] * counts.index).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = [np.fromiter(line.split(), int) for line in open(\"inputs/2.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(502)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_safe(report):\n",
    "    changes = np.diff(report)\n",
    "    signs = np.sign(changes)\n",
    "    return signs[0] != 0 and (signs == signs[0]).all() and (np.abs(changes) <= 3).all()\n",
    "\n",
    "\n",
    "sum(map(is_safe, reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def are_valid_changes(changes, possible_sign):\n",
    "    return (np.sign(changes) == possible_sign) & (np.abs(changes) <= 3)\n",
    "\n",
    "\n",
    "def is_safe_with_dampener(report):\n",
    "    if report.size < 3:\n",
    "        return True\n",
    "\n",
    "    changes = np.diff(report)\n",
    "    for possible_sign in [-1, 1]:\n",
    "        errors = ~are_valid_changes(changes, possible_sign)\n",
    "        n_errors = errors.sum()\n",
    "        if n_errors > 2:\n",
    "            continue\n",
    "        elif n_errors == 2:\n",
    "            idcs = np.nonzero(errors)[0]\n",
    "            if idcs[0] + 1 != idcs[1] or not are_valid_changes(changes[idcs[0]] + changes[idcs[1]], possible_sign):\n",
    "                continue\n",
    "        elif n_errors == 1:\n",
    "            idx = np.argmax(errors)\n",
    "            if (\n",
    "                idx != 0\n",
    "                and idx != changes.size - 1\n",
    "                and not are_valid_changes(changes[idx] + changes[idx + 1], possible_sign)\n",
    "                and not are_valid_changes(changes[idx - 1] + changes[idx], possible_sign)\n",
    "            ):\n",
    "                continue\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "sum(map(is_safe_with_dampener, reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = open(\"inputs/3.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180233229"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(int(a) * int(b) for a, b in re.findall(r\"mul\\(([0-9]+),([0-9]+)\\)\", memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95411583"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_with_conditionals(memory):\n",
    "    total_sum = 0\n",
    "    enabled = True\n",
    "    for a, b, do_string, dont_string in re.findall(r\"mul\\(([0-9]+),([0-9]+)\\)|(do\\(\\))|(don't\\(\\))\", memory):\n",
    "        if a:\n",
    "            if enabled:\n",
    "                total_sum += int(a) * int(b)\n",
    "        elif do_string:\n",
    "            enabled = True\n",
    "        elif dont_string:\n",
    "            enabled = False\n",
    "    return total_sum\n",
    "\n",
    "\n",
    "calc_with_conditionals(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = np.array(list(map(list, open(\"inputs/4.txt\").read().split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_xmas(text, words=(\"XMAS\", \"SAMX\")):\n",
    "    total_count = 0\n",
    "    n, m = text.shape\n",
    "\n",
    "    for view in [\n",
    "        text,\n",
    "        text.T,\n",
    "        [np.diagonal(text, offset=offset) for offset in range(-n + 1, m)],\n",
    "        [np.diagonal(np.flipud(text), offset=offset) for offset in range(-n + 1, m)],\n",
    "    ]:\n",
    "        total_count += sum(\"\".join(line).count(word) for line in view for word in words)\n",
    "\n",
    "    return total_count\n",
    "\n",
    "\n",
    "count_xmas(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1921"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_max(text):\n",
    "    total_count = 0\n",
    "    n, m = text.shape\n",
    "    for i_min in range(n - 2):\n",
    "        for j_min in range(m - 2):\n",
    "            if text[i_min + 1, j_min + 1] == \"A\":\n",
    "                i_max = i_min + 2\n",
    "                j_max = j_min + 2\n",
    "                diag_txt = text[[i_min, i_min, i_max, i_max], [j_min, j_max, j_min, j_max]]\n",
    "                if diag_txt[0] != diag_txt[3] and np.count_nonzero(diag_txt == \"S\") == 2 and np.count_nonzero(diag_txt == \"M\") == 2:\n",
    "                    total_count += 1\n",
    "    return total_count\n",
    "\n",
    "\n",
    "count_max(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_txt, updates_txt = open(\"inputs/5.txt\").read().split(\"\\n\\n\")\n",
    "rules = [(int(x), int(y)) for x, y in (rule.split(\"|\") for rule in rules_txt.split())]\n",
    "updates = [[int(x) for x in line.split(\",\")] for line in updates_txt.split()]\n",
    "succeeding_pages = defaultdict(set)\n",
    "for rule in rules:\n",
    "    succeeding_pages[rule[0]].add(rule[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6384\n"
     ]
    }
   ],
   "source": [
    "def is_correctly_ordered(update):\n",
    "    return not any(x in succeeding_pages[y] for x, y in combinations(update, 2))\n",
    "\n",
    "\n",
    "def middle_page(update):\n",
    "    return update[(len(update) - 1) // 2]\n",
    "\n",
    "\n",
    "total_sum = sum(middle_page(update) for update in updates if is_correctly_ordered(update))\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5353"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "\n",
    "def fix_update(update):\n",
    "    update = copy(update)\n",
    "    for i, _ in enumerate(update):\n",
    "        j = i + 1\n",
    "        while j < len(update):\n",
    "            if update[i] in succeeding_pages[update[j]]:\n",
    "                update[i], update[j] = update[j], update[i]\n",
    "                j = i + 1\n",
    "            else:\n",
    "                j += 1\n",
    "    return update\n",
    "\n",
    "\n",
    "incorrect_updates = (update for update in updates if not is_correctly_ordered(update))\n",
    "sum(middle_page(fix_update(update)) for update in incorrect_updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5269"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Grid:\n",
    "    def __init__(self, grid_txt):\n",
    "        self.grid = np.array(list(map(list, grid_txt.split())))\n",
    "        self.n, self.m = self.grid.shape\n",
    "        self.reset_history()\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.history = np.zeros((*self.grid.shape, 4), bool)\n",
    "\n",
    "    def get(self, pos):\n",
    "        return self.grid[tuple(pos)]\n",
    "\n",
    "    def move_forward(self, pos, direction):\n",
    "        return pos + get_dx(direction)\n",
    "\n",
    "    def next_state(self, pos, direction):\n",
    "        new_pos = self.move_forward(pos, direction)\n",
    "        if self.out_of_bounds(new_pos):\n",
    "            return new_pos, direction, True\n",
    "        if self.get(new_pos) == \"#\":\n",
    "            direction = rotate_right(direction)\n",
    "        else:\n",
    "            pos = new_pos\n",
    "        return pos, direction, False\n",
    "\n",
    "    def find_guard_position(self):\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                if self.grid[i, j] != \".\" and self.grid[i, j] != \"#\":\n",
    "                    return i, j\n",
    "        return -1, -1\n",
    "\n",
    "    def out_of_bounds(self, pos):\n",
    "        return pos[0] < 0 or pos[0] >= self.n or pos[1] < 0 or pos[1] >= self.m\n",
    "\n",
    "    def mark_visited(self, pos, direction):\n",
    "        self.history[pos[0], pos[1], direction.value] = True\n",
    "\n",
    "    def already_visited(self, pos, direction):\n",
    "        return self.history[pos[0], pos[1], direction.value]\n",
    "\n",
    "    def count_visited(self):\n",
    "        return np.count_nonzero(self.history.any(axis=2))\n",
    "\n",
    "\n",
    "def distinct_positions(grid_txt):\n",
    "    grid = Grid(grid_txt)\n",
    "    pos = np.array(grid.find_guard_position())\n",
    "    direction = get_direction(grid.get(pos))\n",
    "    out_of_bounds = False\n",
    "\n",
    "    while not out_of_bounds:\n",
    "        grid.mark_visited(pos, direction)\n",
    "        pos, direction, out_of_bounds = grid.next_state(pos, direction)\n",
    "\n",
    "    return grid.count_visited()\n",
    "\n",
    "\n",
    "grid_txt = open(\"inputs/6.txt\").read()\n",
    "distinct_positions(grid_txt)  # 5269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def looping_obstacles(grid_txt):\n",
    "    n_looping_obstacles = 0\n",
    "    grid = Grid(grid_txt)\n",
    "    initial_pos = np.array(grid.find_guard_position())\n",
    "    initial_direction = get_direction(grid.get(initial_pos))\n",
    "\n",
    "    for i in range(grid.n):\n",
    "        for j in range(grid.m):\n",
    "            if grid.grid[i, j] != \".\":\n",
    "                continue\n",
    "\n",
    "            grid.reset_history()\n",
    "            grid.grid[i, j] = \"#\"\n",
    "            pos = initial_pos\n",
    "            direction = initial_direction\n",
    "            out_of_bounds = False\n",
    "            while not out_of_bounds:\n",
    "                if grid.already_visited(pos, direction):\n",
    "                    n_looping_obstacles += 1\n",
    "                    break\n",
    "                grid.mark_visited(pos, direction)\n",
    "                pos, direction, out_of_bounds = grid.next_state(pos, direction)\n",
    "\n",
    "            grid.grid[i, j] = \".\"\n",
    "\n",
    "    return n_looping_obstacles\n",
    "\n",
    "\n",
    "looping_obstacles(grid_txt)  # 1957\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equations(equations_txt):\n",
    "    return [\n",
    "        (int(test), np.fromstring(numbers, int, sep=\" \"))\n",
    "        for test, numbers in (equation.split(\": \") for equation in equations_txt.splitlines())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20281182715321"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_combinations(test, numbers, current_value=0):\n",
    "    if numbers.size == 0:\n",
    "        return test == current_value\n",
    "    if current_value > test:\n",
    "        return False\n",
    "    return check_combinations(test, numbers[1:], current_value=current_value + numbers[0]) or check_combinations(\n",
    "        test, numbers[1:], current_value=current_value * numbers[0]\n",
    "    )\n",
    "\n",
    "\n",
    "equations_txt = open(\"inputs/7.txt\").read()\n",
    "equations = get_equations(equations_txt)\n",
    "\n",
    "sum(test for test, numbers in equations if check_combinations(test, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_combinations_with_concat(test, numbers, current_value=0):\n",
    "    if numbers.size == 0:\n",
    "        return test == current_value\n",
    "    if current_value > test:\n",
    "        return False\n",
    "    return (\n",
    "        check_combinations_with_concat(test, numbers[1:], current_value=current_value + numbers[0])\n",
    "        or check_combinations_with_concat(test, numbers[1:], current_value=current_value * numbers[0])\n",
    "        or check_combinations_with_concat(test, numbers[1:], current_value=int(str(current_value) + str(numbers[0])))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159490400628354"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test for test, numbers in equations if check_combinations_with_concat(test, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_antenna_locs(antenna_map):\n",
    "    locs = defaultdict(list)\n",
    "    for i, line in enumerate(antenna_map):\n",
    "        for j, symbol in enumerate(line):\n",
    "            if symbol != \".\":\n",
    "                locs[symbol].append(np.array([i, j]))\n",
    "    return locs\n",
    "\n",
    "\n",
    "antenna_map_txt = open(\"inputs/8.txt\").read()\n",
    "\n",
    "antenna_map_example_txt = \"\"\"\\\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def within_bounds(coords, max_coords):\n",
    "    return (coords >= 0).all() and (coords < max_coords).all()\n",
    "\n",
    "\n",
    "def get_n_antinodes(antenna_map_txt):\n",
    "    antenna_map = antenna_map_txt.splitlines()\n",
    "    antenna_locs = get_antenna_locs(antenna_map)\n",
    "\n",
    "    antinode_locs = set()\n",
    "    max_coords = np.array([len(antenna_map), len(antenna_map[0])])\n",
    "    for freq_locs in antenna_locs.values():\n",
    "        for c1, c2 in combinations(freq_locs, 2):\n",
    "            diff = c2 - c1\n",
    "            for antinode in (c1 - diff, c2 + diff):\n",
    "                if within_bounds(antinode, max_coords):\n",
    "                    antinode_locs.add(tuple(antinode))\n",
    "\n",
    "    return len(antinode_locs)\n",
    "\n",
    "\n",
    "get_n_antinodes(antenna_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_resonant_antinodes(antenna_map_txt):\n",
    "    antenna_map = antenna_map_txt.splitlines()\n",
    "    antenna_locs = get_antenna_locs(antenna_map)\n",
    "\n",
    "    antinode_locs = set()\n",
    "    max_coords = np.array([len(antenna_map), len(antenna_map[0])])\n",
    "\n",
    "    for freq_locs in antenna_locs.values():\n",
    "        for c1, c2 in combinations(freq_locs, 2):\n",
    "            for pos, offset in ((c1.copy(), c1 - c2), (c2.copy(), c2 - c1)):\n",
    "                while within_bounds(pos, max_coords):\n",
    "                    antinode_locs.add(tuple(pos))\n",
    "                    pos += offset\n",
    "    return len(antinode_locs)\n",
    "\n",
    "\n",
    "get_n_resonant_antinodes(antenna_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_map_txt = open(\"inputs/9.txt\").read()[:-1]\n",
    "\n",
    "\n",
    "def position_sum(curr_pos, new_pos):\n",
    "    return (new_pos + curr_pos - 1) * (new_pos - curr_pos) // 2\n",
    "\n",
    "\n",
    "def update_checksum_and_position(checksum, curr_pos, digit, digit_idx):\n",
    "    new_pos = curr_pos + digit\n",
    "    checksum += digit_idx * position_sum(curr_pos, new_pos)\n",
    "    return checksum, new_pos\n",
    "\n",
    "\n",
    "def reordered_checksum(disk_map_txt):\n",
    "    digits = list(map(int, disk_map_txt[::2]))\n",
    "    spaces = list(map(int, disk_map_txt[1::2]))\n",
    "    checksum = 0\n",
    "    curr_pos = 0\n",
    "    end_idx = len(digits) - 1\n",
    "    for idx, _ in enumerate(digits):\n",
    "        checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, digits[idx], idx)\n",
    "\n",
    "        if end_idx <= idx:\n",
    "            break\n",
    "\n",
    "        while end_idx > idx and spaces[idx] > 0:\n",
    "            filled_positions = min(digits[end_idx], spaces[idx])\n",
    "            spaces[idx] -= filled_positions\n",
    "            digits[end_idx] -= filled_positions\n",
    "            checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, filled_positions, end_idx)\n",
    "            if digits[end_idx] == 0:\n",
    "                end_idx -= 1\n",
    "\n",
    "    return checksum\n",
    "\n",
    "\n",
    "disk_map_example_txt = \"2333133121414131402\"\n",
    "reordered_checksum(disk_map_example_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6408966547049"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def defragmented_checksum(disk_map_txt):\n",
    "    digits_per_pos = [[(dig_id, int(symbol))] for dig_id, symbol in enumerate(disk_map_txt[::2])]\n",
    "    spaces = list(map(int, disk_map_txt[1::2])) + [0]\n",
    "\n",
    "    for end_idx, _ in reversed(list(enumerate(digits_per_pos))):\n",
    "        dig_id, digit = digits_per_pos[end_idx][0]\n",
    "        for space_idx, _ in enumerate(spaces):\n",
    "            if space_idx >= end_idx:\n",
    "                break\n",
    "            if spaces[space_idx] >= digit:\n",
    "                spaces[space_idx] -= digit\n",
    "                digits_per_pos[space_idx].append((dig_id, digit))\n",
    "                spaces[dig_id - 1] += digit\n",
    "                digits_per_pos[dig_id][0] = (dig_id, 0)\n",
    "                break\n",
    "\n",
    "    curr_pos = 0\n",
    "    checksum = 0\n",
    "    for idx, digit_list in enumerate(digits_per_pos):\n",
    "        for dig_id, digit in digit_list:\n",
    "            checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, digit, dig_id)\n",
    "        curr_pos += spaces[idx]\n",
    "\n",
    "    return checksum\n",
    "\n",
    "\n",
    "defragmented_checksum(disk_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_map_txt = open(\"inputs/10.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_score(topo_map_txt):\n",
    "    topo_map = np.array([list(map(int, line)) for line in topo_map_txt.splitlines()])\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= topo_map.shape[0] or j >= topo_map.shape[1]\n",
    "\n",
    "    deltas = np.array(\n",
    "        [\n",
    "            [0, 1],\n",
    "            [1, 0],\n",
    "            [0, -1],\n",
    "            [-1, 0],\n",
    "        ]\n",
    "    )\n",
    "    score = 0\n",
    "    trailheads = np.argwhere(topo_map == 0)\n",
    "    for trailhead in trailheads:\n",
    "        visited = np.zeros_like(topo_map, dtype=bool)\n",
    "        stack = [trailhead]\n",
    "        while stack:\n",
    "            top = stack.pop()\n",
    "            if visited[tuple(top)]:\n",
    "                continue\n",
    "\n",
    "            if topo_map[tuple(top)] == 9:\n",
    "                score += 1\n",
    "            visited[tuple(top)] = True\n",
    "            for delta in deltas:\n",
    "                new_pos = top + delta\n",
    "                if (\n",
    "                    not out_of_bounds(*new_pos)\n",
    "                    and not visited[tuple(new_pos)]\n",
    "                    and topo_map[tuple(new_pos)] == topo_map[tuple(top)] + 1\n",
    "                ):\n",
    "                    stack.append(new_pos)\n",
    "    return score\n",
    "\n",
    "\n",
    "map_score(topo_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1324)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_score(topo_map_txt):\n",
    "    topo_map = np.array([list(map(int, line)) for line in topo_map_txt.splitlines()])\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= topo_map.shape[0] or j >= topo_map.shape[1]\n",
    "\n",
    "    deltas = np.array(\n",
    "        [\n",
    "            [0, 1],\n",
    "            [1, 0],\n",
    "            [0, -1],\n",
    "            [-1, 0],\n",
    "        ]\n",
    "    )\n",
    "    score = 0\n",
    "    trailheads = np.argwhere(topo_map == 0)\n",
    "\n",
    "    visited = np.zeros_like(topo_map, dtype=int)\n",
    "    for pos in trailheads:\n",
    "        visited[tuple(pos)] = 1\n",
    "    new_stack = list(trailheads)\n",
    "    height = 0\n",
    "\n",
    "    while new_stack:\n",
    "        stack = new_stack\n",
    "        new_stack = []\n",
    "        for pos in stack:\n",
    "            for delta in deltas:\n",
    "                new_pos = pos + delta\n",
    "                if not out_of_bounds(*new_pos) and topo_map[tuple(new_pos)] == height + 1:\n",
    "                    if not visited[tuple(new_pos)]:\n",
    "                        new_stack.append(new_pos)\n",
    "                    visited[tuple(new_pos)] += visited[tuple(pos)]\n",
    "        height += 1\n",
    "\n",
    "    score = sum(visited[tuple(pos)] for pos in np.argwhere(topo_map == 9))\n",
    "    return score\n",
    "\n",
    "\n",
    "map_score(topo_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190865"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evolve(number):\n",
    "    if number == 0:\n",
    "        return [1]\n",
    "\n",
    "    digits = str(number)\n",
    "    n_digits = len(digits)\n",
    "    if n_digits % 2 == 0:\n",
    "        return [int(digits[: n_digits // 2]), int(digits[n_digits // 2 :])]\n",
    "\n",
    "    return [number * 2024]\n",
    "\n",
    "\n",
    "def get_n_stones(stones_txt, n_blinks=25):\n",
    "    stone_counts = dict(Counter(map(int, stones_txt.split())))\n",
    "\n",
    "    for i in range(n_blinks):\n",
    "        next_counts = defaultdict(int)\n",
    "        for number, count in stone_counts.items():\n",
    "            for evolved_number in evolve(number):\n",
    "                next_counts[evolved_number] += count\n",
    "        stone_counts = next_counts\n",
    "    return sum(stone_counts.values())\n",
    "\n",
    "\n",
    "stones_txt = open(\"inputs/11.txt\").read()\n",
    "\n",
    "get_n_stones(stones_txt, n_blinks=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225404711855335"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_stones(stones_txt, n_blinks=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delta(coords, delta):\n",
    "    return (coords[0] + delta[0], coords[1] + delta[1])\n",
    "\n",
    "\n",
    "def fencing_price(garden_txt):\n",
    "    garden = np.array(list(map(list, garden_txt.split())))\n",
    "\n",
    "    visited = np.zeros_like(garden, dtype=bool)\n",
    "    deltas = (\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (1, 0),\n",
    "        (0, -1),\n",
    "    )\n",
    "\n",
    "    def is_connected(nb_coords, plant_type):\n",
    "        return not out_of_bounds(*nb_coords) and garden[nb_coords] == plant_type\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= garden.shape[0] or j >= garden.shape[1]\n",
    "\n",
    "    def dfs(coords, plant_type, component):\n",
    "        component.append(coords)\n",
    "        visited[coords] = True\n",
    "        perimeter = 4\n",
    "        for delta in deltas:\n",
    "            nb_coords = add_delta(coords, delta)\n",
    "            if is_connected(nb_coords, plant_type):\n",
    "                perimeter -= 1\n",
    "                if not visited[nb_coords]:\n",
    "                    perimeter += dfs(nb_coords, plant_type, component)\n",
    "        return perimeter\n",
    "\n",
    "    price = 0\n",
    "    for coords, curr_plot in np.ndenumerate(garden):\n",
    "        if not visited[coords]:\n",
    "            connected_component = []\n",
    "            perimeter = dfs(coords, curr_plot, connected_component)\n",
    "            price += len(connected_component) * perimeter\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464678"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garden_txt = open(\"inputs/12.txt\").read()\n",
    "\n",
    "fencing_price(garden_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877492"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discounted_fencing_price(garden_txt):\n",
    "    garden = np.array(list(map(list, garden_txt.split())))\n",
    "\n",
    "    visited = np.zeros_like(garden, dtype=bool)\n",
    "    deltas = (\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (1, 0),\n",
    "        (0, -1),\n",
    "    )\n",
    "\n",
    "    def is_connected(nb_coords, plant_type):\n",
    "        return not out_of_bounds(*nb_coords) and garden[nb_coords] == plant_type\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= garden.shape[0] or j >= garden.shape[1]\n",
    "\n",
    "    def dfs(coords, plant_type, component):\n",
    "        component.append(coords)\n",
    "        visited[coords] = True\n",
    "\n",
    "        for delta in deltas:\n",
    "            nb_coords = add_delta(coords, delta)\n",
    "            if is_connected(nb_coords, plant_type):\n",
    "                if not visited[nb_coords]:\n",
    "                    dfs(nb_coords, plant_type, component)\n",
    "\n",
    "    price = 0\n",
    "    for coords, curr_plot in np.ndenumerate(garden):\n",
    "        if not visited[coords]:\n",
    "            connected_component = []\n",
    "            dfs(coords, curr_plot, connected_component)\n",
    "            sides = 0\n",
    "            for i, coords in enumerate(connected_component):\n",
    "                for direction in Direction:\n",
    "                    delta = deltas[direction.value]\n",
    "                    if not is_connected(add_delta(coords, delta), curr_plot):\n",
    "                        left_rotated_nb_coords = add_delta(coords, deltas[rotate_left(direction).value])\n",
    "                        if not is_connected(left_rotated_nb_coords, curr_plot) or is_connected(\n",
    "                            add_delta(left_rotated_nb_coords, delta), curr_plot\n",
    "                        ):\n",
    "                            sides += 1\n",
    "\n",
    "            price += len(connected_component) * sides\n",
    "    return price\n",
    "\n",
    "\n",
    "discounted_fencing_price(garden_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(37686)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_machine_input(line):\n",
    "    return re.findall(r\"Button A: X\\+([0-9]+), Y\\+([0-9]+)\\nButton B: X\\+([0-9]+), Y\\+([0-9]+)\\nPrize: X=([0-9]+), Y=([0-9]+)\", line)[\n",
    "        0\n",
    "    ]\n",
    "\n",
    "\n",
    "def min_tokens(machine_input_line, fix_unit_conversion=False):\n",
    "    x_a, y_a, x_b, y_b, price_x, price_y = map(int, process_machine_input(machine_input_line))\n",
    "    A = np.array(\n",
    "        [\n",
    "            [x_a, x_b],\n",
    "            [y_a, y_b],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    assert np.linalg.det(A) != 0\n",
    "\n",
    "    p = np.array([price_x, price_y])\n",
    "    if fix_unit_conversion:\n",
    "        p += 10000000000000\n",
    "\n",
    "    n_tokens = np.linalg.solve(A, p).round().astype(int)\n",
    "\n",
    "    if not np.array_equal(A @ n_tokens, p):\n",
    "        return 0\n",
    "\n",
    "    return 3 * n_tokens[0] + n_tokens[1]\n",
    "\n",
    "\n",
    "machine_inputs_txt = open(\"inputs/13.txt\").read()[:-1].split(\"\\n\\n\")\n",
    "sum(map(min_tokens, machine_inputs_txt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(77204516023437)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(min_tokens(line, fix_unit_conversion=True) for line in machine_inputs_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_inputs_txt = open(\"inputs/14.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209409792"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safety_factor(robot_inputs_txt, bathroom_shape, n_seconds=100):\n",
    "    bathroom_shape = np.array(bathroom_shape)\n",
    "    positions, velocities = np.split(\n",
    "        np.array(re.findall(r\"p=([0-9]+),([0-9]+) v=(-?[0-9]+),(-?[0-9]+)\", robot_inputs_txt), dtype=int),\n",
    "        2,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    new_positions = (positions + velocities * n_seconds) % bathroom_shape\n",
    "    split_lines = bathroom_shape // 2\n",
    "\n",
    "    ans = 1\n",
    "    for in_quadrant in [\n",
    "        (new_positions[:, 0] < split_lines[0]) & (new_positions[:, 1] < split_lines[1]),\n",
    "        (new_positions[:, 0] < split_lines[0]) & (new_positions[:, 1] > split_lines[1]),\n",
    "        (new_positions[:, 0] > split_lines[0]) & (new_positions[:, 1] < split_lines[1]),\n",
    "        (new_positions[:, 0] > split_lines[0]) & (new_positions[:, 1] > split_lines[1]),\n",
    "    ]:\n",
    "        ans *= np.count_nonzero(in_quadrant)\n",
    "    return ans\n",
    "\n",
    "\n",
    "safety_factor(robot_inputs_txt, (101, 103))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8006"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def largest_component(positions, bathroom_shape):\n",
    "    grid = np.zeros(bathroom_shape, int)\n",
    "    np.add.at(grid, (positions[:, 0], positions[:, 1]), 1)\n",
    "\n",
    "    assert np.sum(grid) == len(positions)\n",
    "    visited = np.zeros(grid.shape, bool)\n",
    "\n",
    "    def dfs(coords, n_robots):\n",
    "        if visited[coords]:\n",
    "            return n_robots\n",
    "        visited[coords] = True\n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                if dx == 0 and dy == 0:\n",
    "                    continue\n",
    "\n",
    "                x_next = coords[0] + dx\n",
    "                y_next = coords[1] + dy\n",
    "                if x_next < 0 or y_next < 0 or x_next >= bathroom_shape[0] or y_next >= bathroom_shape[1]:\n",
    "                    continue\n",
    "                if grid[x_next, y_next] > 0:\n",
    "                    n_robots = dfs((x_next, y_next), n_robots)\n",
    "        return n_robots + 1\n",
    "\n",
    "    return max(dfs((x, y), 0) for x, y in positions)\n",
    "\n",
    "\n",
    "def christmas_tree_time(robot_inputs_txt, bathroom_shape, t_max=100, verbose=False):\n",
    "    bathroom_shape = np.array(bathroom_shape)\n",
    "    positions, velocities = np.split(\n",
    "        np.array(re.findall(r\"p=([0-9]+),([0-9]+) v=(-?[0-9]+),(-?[0-9]+)\", robot_inputs_txt), dtype=int),\n",
    "        2,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    best_so_far = 1\n",
    "    for t in range(1, t_max + 1):\n",
    "        positions = (positions + velocities) % bathroom_shape\n",
    "        conn = largest_component(positions, bathroom_shape)\n",
    "        if conn > best_so_far:\n",
    "            if conn > positions.shape[0] * 0.1:\n",
    "                if verbose:\n",
    "                    grid = np.zeros(bathroom_shape, int)\n",
    "                    np.add.at(grid, (positions[:, 0], positions[:, 1]), 1)\n",
    "                    for line in grid.T:\n",
    "                        print(\"\".join([str(val) if val > 0 else \" \" for val in line]))\n",
    "                return t\n",
    "            best_so_far = conn\n",
    "    return -1\n",
    "\n",
    "\n",
    "christmas_tree_time(robot_inputs_txt, (101, 103), t_max=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_txt = open(\"inputs/15.txt\").read()[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1426855)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def move_boxes(grid, pos, dx):\n",
    "    new_pos = pos + dx\n",
    "    while (new_pos >= 0).all() and (new_pos < grid.shape).all() and grid[tuple(new_pos)] != \"#\":\n",
    "        if grid[tuple(new_pos)] == \".\":\n",
    "            return new_pos\n",
    "\n",
    "        new_pos += dx\n",
    "    return None\n",
    "\n",
    "\n",
    "def simulate_warehouse(grid, dx_vecs):\n",
    "    robot_pos = np.argwhere(grid == \"@\")[0]\n",
    "    for dx in dx_vecs:\n",
    "        new_pos = robot_pos + dx\n",
    "        if grid[tuple(new_pos)] == \"#\":\n",
    "            continue\n",
    "        if grid[tuple(new_pos)] == \"O\":\n",
    "            new_box_position = move_boxes(grid, new_pos, dx)\n",
    "            if new_box_position is None:\n",
    "                continue\n",
    "            grid[tuple(new_box_position)] = \"O\"\n",
    "        grid[tuple(new_pos)] = \"@\"\n",
    "        grid[tuple(robot_pos)] = \".\"\n",
    "        robot_pos = new_pos\n",
    "\n",
    "\n",
    "def gps_sum(warehouse_txt):\n",
    "    grid_txt, instructions_txt = warehouse_txt.split(\"\\n\\n\")\n",
    "    instructions_txt = instructions_txt.replace(\"\\n\", \"\")\n",
    "    grid = np.array(list(map(list, grid_txt.split())))\n",
    "    dx_vecs = [get_dx(get_direction(instruction)) for instruction in instructions_txt]\n",
    "    simulate_warehouse(grid, dx_vecs)\n",
    "\n",
    "    box_coords = np.argwhere(grid == \"O\")\n",
    "    return 100 * np.sum(box_coords[:, 0]) + np.sum(box_coords[:, 1])\n",
    "\n",
    "\n",
    "gps_sum(warehouse_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1404917)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def move_scaled_boxes(grid, pos, direction, box_coords, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    box_positions = (pos, pos + get_dx(Direction.RIGHT)) if grid[tuple(pos)] == \"[\" else (pos + get_dx(Direction.LEFT), pos)\n",
    "    if tuple(box_positions[0]) in visited:\n",
    "        return True\n",
    "    visited.add(tuple(box_positions[0]))\n",
    "    dx = get_dx(direction)\n",
    "\n",
    "    new_left_pos = box_positions[0] + dx\n",
    "    new_right_pos = box_positions[1] + dx\n",
    "\n",
    "    if grid[tuple(new_left_pos)] == \"#\" or grid[tuple(new_right_pos)] == \"#\":\n",
    "        return False\n",
    "\n",
    "    if direction in [Direction.UP, Direction.DOWN]:\n",
    "        if grid[tuple(new_left_pos)] == \"[\":\n",
    "            if not move_scaled_boxes(grid, new_left_pos, direction, box_coords, visited=visited):\n",
    "                return False\n",
    "        else:\n",
    "            if grid[tuple(new_left_pos)] == \"]\":\n",
    "                if not move_scaled_boxes(grid, new_left_pos, direction, box_coords, visited=visited):\n",
    "                    return False\n",
    "\n",
    "            if grid[tuple(new_right_pos)] == \"[\":\n",
    "                if not move_scaled_boxes(grid, new_right_pos, direction, box_coords, visited=visited):\n",
    "                    return False\n",
    "    else:\n",
    "        new_pos = new_left_pos if direction == Direction.LEFT else new_right_pos\n",
    "        if grid[tuple(new_pos)] != \".\" and not move_scaled_boxes(grid, new_pos, direction, box_coords, visited=visited):\n",
    "            return False\n",
    "\n",
    "    box_coords.append(box_positions)\n",
    "    return True\n",
    "\n",
    "\n",
    "def simulate_scaled_warehouse(grid, directions):\n",
    "    robot_pos = np.argwhere(grid == \"@\")[0]\n",
    "    for direction in directions:\n",
    "        dx = get_dx(direction)\n",
    "        new_pos = robot_pos + dx\n",
    "        if grid[tuple(new_pos)] == \"#\":\n",
    "            continue\n",
    "        if grid[tuple(new_pos)] in \"[]\":\n",
    "            original_boxes_coords = []\n",
    "            if not move_scaled_boxes(grid, new_pos, direction, original_boxes_coords):\n",
    "                continue\n",
    "            assert len(original_boxes_coords) > 0\n",
    "            for left_box_coords, right_box_coords in original_boxes_coords:\n",
    "                grid[tuple(left_box_coords)] = \".\"\n",
    "                grid[tuple(right_box_coords)] = \".\"\n",
    "                grid[tuple(left_box_coords + dx)] = \"[\"\n",
    "                grid[tuple(right_box_coords + dx)] = \"]\"\n",
    "\n",
    "        grid[tuple(new_pos)] = \"@\"\n",
    "        grid[tuple(robot_pos)] = \".\"\n",
    "        robot_pos = new_pos\n",
    "\n",
    "\n",
    "def scaled_gps_sum(warehouse_txt):\n",
    "    grid_txt, instructions_txt = warehouse_txt.split(\"\\n\\n\")\n",
    "    grid_txt = grid_txt.replace(\"#\", \"##\").replace(\".\", \"..\").replace(\"O\", \"[]\").replace(\"@\", \"@.\")\n",
    "    instructions_txt = instructions_txt.replace(\"\\n\", \"\")\n",
    "    grid = np.array(list(map(list, grid_txt.split())))\n",
    "    directions = [get_direction(instruction) for instruction in instructions_txt]\n",
    "    simulate_scaled_warehouse(grid, directions)\n",
    "\n",
    "    box_coords = np.argwhere(grid == \"[\")\n",
    "    return 100 * np.sum(box_coords[:, 0]) + np.sum(box_coords[:, 1])\n",
    "\n",
    "\n",
    "scaled_gps_sum(warehouse_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze_txt = open(\"inputs/16.txt\").read()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123540"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass(order=True, frozen=True)\n",
    "class MazeState:\n",
    "    dist: int\n",
    "    coords: np.array = field(compare=False)\n",
    "    direction: Direction = field(compare=False)\n",
    "\n",
    "    def next_states(self):\n",
    "        left_direction = rotate_left(self.direction)\n",
    "        right_direction = rotate_right(self.direction)\n",
    "        return (\n",
    "            MazeState(self.dist + 1, self.coords + get_dx(self.direction), self.direction),\n",
    "            MazeState(self.dist + 1001, self.coords + get_dx(left_direction), left_direction),\n",
    "            MazeState(self.dist + 1001, self.coords + get_dx(right_direction), right_direction),\n",
    "        )\n",
    "\n",
    "    def get_idx_tuple(self):\n",
    "        return (*self.coords, self.direction.value)\n",
    "\n",
    "\n",
    "def best_maze_score(maze_txt):\n",
    "    grid = np.array(list(map(list, maze_txt.split())))\n",
    "    start_state = MazeState(0, np.argwhere(grid == \"S\")[0], Direction.RIGHT)\n",
    "    end_coords = np.argwhere(grid == \"E\")[0]\n",
    "\n",
    "    dist = np.full((*grid.shape, 4), np.iinfo(int).max, dtype=int)\n",
    "    queue = [start_state]\n",
    "    while queue:\n",
    "        state = heappop(queue)\n",
    "        if (state.coords == end_coords).all():\n",
    "            return state.dist\n",
    "\n",
    "        for next_state in state.next_states():\n",
    "            next_idx_tuple = next_state.get_idx_tuple()\n",
    "            if grid[tuple(next_state.coords)] != \"#\" and next_state.dist < dist[next_idx_tuple]:\n",
    "                dist[next_idx_tuple] = next_state.dist\n",
    "                heappush(queue, next_state)\n",
    "    return -1\n",
    "\n",
    "\n",
    "best_maze_score(maze_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shortest_path_tiles(maze_txt):\n",
    "    grid = np.array(list(map(list, maze_txt.split())))\n",
    "    start_state = MazeState(0, np.argwhere(grid == \"S\")[0], Direction.RIGHT)\n",
    "    end_coords = np.argwhere(grid == \"E\")[0]\n",
    "    max_dist = np.iinfo(int).max\n",
    "    dist = np.full((*grid.shape, 4), max_dist, dtype=int)\n",
    "    prev = defaultdict(list)\n",
    "    queue = [start_state]\n",
    "    while queue:\n",
    "        state = heappop(queue)\n",
    "        if state.dist > max_dist:\n",
    "            break\n",
    "        if (state.coords == end_coords).all():\n",
    "            max_dist = state.dist\n",
    "\n",
    "        idx_tuple = state.get_idx_tuple()\n",
    "\n",
    "        for next_state in state.next_states():\n",
    "            next_idx_tuple = next_state.get_idx_tuple()\n",
    "            if grid[tuple(next_state.coords)] != \"#\":\n",
    "                if next_state.dist == dist[next_idx_tuple]:\n",
    "                    prev[next_idx_tuple].append(idx_tuple)\n",
    "                elif next_state.dist < dist[next_idx_tuple]:\n",
    "                    prev[next_idx_tuple] = [idx_tuple]\n",
    "                    dist[next_idx_tuple] = next_state.dist\n",
    "                    heappush(queue, next_state)\n",
    "\n",
    "    visited = np.zeros_like(dist, dtype=bool)\n",
    "    stack = []\n",
    "    for direction in Direction:\n",
    "        idx_tuple = (*end_coords, direction.value)\n",
    "        if idx_tuple in prev:\n",
    "            stack.append(idx_tuple)\n",
    "\n",
    "    while stack:\n",
    "        idx_tuple = stack.pop()\n",
    "        if visited[idx_tuple]:\n",
    "            continue\n",
    "        visited[idx_tuple] = True\n",
    "        for prev_tuple in prev[idx_tuple]:\n",
    "            stack.append(prev_tuple)\n",
    "\n",
    "    return np.count_nonzero(visited.any(axis=-1))\n",
    "\n",
    "\n",
    "shortest_path_tiles(maze_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_txt = open(\"inputs/17.txt\").read()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,3,4,7,5,7,3,0,7'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_program(program_txt):\n",
    "    register_txt, opcodes_txt = program_txt.split(\"\\n\\n\")\n",
    "    registers = [int(line.split(\": \")[1]) for line in register_txt.splitlines()]\n",
    "    program = list(map(int, opcodes_txt.split(\": \")[1].split(\",\")))\n",
    "    outputs = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(program) - 1:\n",
    "        opcode, operand = program[i : i + 2]\n",
    "        combo = operand if operand < 4 or operand > 6 else registers[operand - 4]\n",
    "        match opcode:\n",
    "            case 0:\n",
    "                registers[0] //= 2**combo\n",
    "            case 1:\n",
    "                registers[1] ^= operand\n",
    "            case 2:\n",
    "                registers[1] = combo & 7\n",
    "            case 3:\n",
    "                if registers[0] != 0:\n",
    "                    i = operand - 2\n",
    "            case 4:\n",
    "                registers[1] ^= registers[2]\n",
    "            case 5:\n",
    "                outputs.append(combo & 7)\n",
    "            case 6:\n",
    "                registers[1] = registers[0] // (2**combo)\n",
    "            case 7:\n",
    "                registers[2] = registers[0] // (2**combo)\n",
    "        i += 2\n",
    "    return \",\".join(map(str, outputs))\n",
    "\n",
    "\n",
    "run_program(program_txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_output_digit(A):\n",
    "    return (A & 7) ^ 5 ^ ((A >> ((A & 7) ^ 2)) & 7)\n",
    "\n",
    "\n",
    "def run_test_program(A_val):\n",
    "    ans = []\n",
    "    while A_val > 0:\n",
    "        ans.append(str(last_output_digit(A_val)))\n",
    "        A_val //= 8\n",
    "    return \",\".join(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190384609508367"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_A_value():\n",
    "    opcodes_txt = program_txt.split(\"Program: \")[1]\n",
    "    program = list(map(int, opcodes_txt.split(\",\")))\n",
    "\n",
    "    def backtrack(idx, curr_A=0):\n",
    "        curr_A *= 8\n",
    "        for i in range(8):\n",
    "            next_A = curr_A + i\n",
    "            if last_output_digit(next_A) == program[-idx - 1]:\n",
    "                if idx == len(program) - 1:\n",
    "                    return next_A\n",
    "                final_A = backtrack(idx + 1, curr_A=next_A)\n",
    "                if final_A is not None:\n",
    "                    return final_A\n",
    "        return None\n",
    "\n",
    "    ans = backtrack(0)\n",
    "    assert run_test_program(ans) == opcodes_txt\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "find_A_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "falling_bytes_txt = open(\"inputs/18.txt\").read()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def memory_grid_steps(falling_bytes_txt, grid_size=71, n_bytes=1024):\n",
    "    byte_grid = np.zeros((grid_size, grid_size), dtype=bool)\n",
    "    falling_bytes = np.roll(\n",
    "        np.genfromtxt(falling_bytes_txt.splitlines(), delimiter=\",\", dtype=int)[:n_bytes],\n",
    "        axis=1,\n",
    "        shift=1,\n",
    "    )\n",
    "    byte_grid[falling_bytes[:, 0], falling_bytes[:, 1]] = 1\n",
    "\n",
    "    visited = np.zeros_like(byte_grid)\n",
    "    start_pos = np.array([0, 0])\n",
    "    end_pos = np.array([grid_size - 1, grid_size - 1])\n",
    "    distance = 0\n",
    "    next_queue = [start_pos]\n",
    "\n",
    "    while next_queue:\n",
    "        queue = next_queue\n",
    "        next_queue = []\n",
    "        distance += 1\n",
    "\n",
    "        for curr_pos in queue:\n",
    "            for direction in Direction:\n",
    "                next_pos = curr_pos + get_dx(direction)\n",
    "                if (\n",
    "                    (next_pos < 0).any()\n",
    "                    or (next_pos >= byte_grid.shape).any()\n",
    "                    or visited[tuple(next_pos)]\n",
    "                    or byte_grid[tuple(next_pos)]\n",
    "                ):\n",
    "                    continue\n",
    "                if (next_pos == end_pos).all():\n",
    "                    return distance\n",
    "                visited[tuple(next_pos)] = True\n",
    "                next_queue.append(next_pos)\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "memory_grid_steps(falling_bytes_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22,50'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def blocking_byte(falling_bytes_txt):\n",
    "    falling_bytes_lines = falling_bytes_txt.splitlines()\n",
    "    low = 1024\n",
    "    high = len(falling_bytes_lines) - 1\n",
    "\n",
    "    while low < high:\n",
    "        mid = (high + low) // 2\n",
    "        if memory_grid_steps(falling_bytes_txt, n_bytes=mid) != -1:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid\n",
    "\n",
    "    return falling_bytes_lines[low - 1]\n",
    "\n",
    "\n",
    "blocking_byte(falling_bytes_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "towels_input_txt = open(\"inputs/19.txt\").read()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(267)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PatternNode:\n",
    "    def __init__(self, pattern=None):\n",
    "        self.children = dict()\n",
    "        self.is_leaf = False\n",
    "        if pattern is None:\n",
    "            self.stripe = \"\"\n",
    "        else:\n",
    "            self.stripe = pattern[0]\n",
    "            self.addChild(pattern[1:])\n",
    "\n",
    "    def addChild(self, pattern):\n",
    "        if pattern:\n",
    "            if pattern[0] not in self.children:\n",
    "                self.children[pattern[0]] = PatternNode(pattern)\n",
    "            else:\n",
    "                self.children[pattern[0]].addChild(pattern[1:])\n",
    "        else:\n",
    "            self.is_leaf = True\n",
    "\n",
    "\n",
    "def is_possible(design, rootNode):\n",
    "    n = len(design)\n",
    "    can_be_reached = np.zeros(n + 1, dtype=bool)\n",
    "    can_be_reached[0] = True\n",
    "    for i in range(n):\n",
    "        if not can_be_reached[i]:\n",
    "            continue\n",
    "        currNode = rootNode\n",
    "        for j in range(i, n):\n",
    "            if design[j] not in currNode.children:\n",
    "                break\n",
    "            currNode = currNode.children[design[j]]\n",
    "            if currNode.is_leaf:\n",
    "                can_be_reached[j + 1] = True\n",
    "    return can_be_reached[-1]\n",
    "\n",
    "\n",
    "def possible_designs(towels_input_txt):\n",
    "    towel_patterns_txt, designs_txt = towels_input_txt.split(\"\\n\\n\")\n",
    "    towel_patterns = towel_patterns_txt.split(\", \")\n",
    "    designs = designs_txt.split(\"\\n\")\n",
    "\n",
    "    root = PatternNode()\n",
    "    for pattern in towel_patterns:\n",
    "        root.addChild(pattern)\n",
    "\n",
    "    return sum(is_possible(design, root) for design in designs)\n",
    "\n",
    "\n",
    "possible_designs(towels_input_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(796449099271652)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n_design_ways(design, rootNode):\n",
    "    n = len(design)\n",
    "    n_ways = np.zeros(n + 1, dtype=int)\n",
    "    n_ways[0] = 1\n",
    "    for i in range(n):\n",
    "        if n_ways[i] == 0:\n",
    "            continue\n",
    "        currNode = rootNode\n",
    "        for j in range(i, n):\n",
    "            if design[j] not in currNode.children:\n",
    "                break\n",
    "            currNode = currNode.children[design[j]]\n",
    "            if currNode.is_leaf:\n",
    "                n_ways[j + 1] += n_ways[i]\n",
    "    return n_ways[-1]\n",
    "\n",
    "\n",
    "def possible_design_ways(towels_input_txt):\n",
    "    towel_patterns_txt, designs_txt = towels_input_txt.split(\"\\n\\n\")\n",
    "    towel_patterns = towel_patterns_txt.split(\", \")\n",
    "    designs = designs_txt.split(\"\\n\")\n",
    "\n",
    "    root = PatternNode()\n",
    "    for pattern in towel_patterns:\n",
    "        root.addChild(pattern)\n",
    "\n",
    "    return sum(n_design_ways(design, root) for design in designs)\n",
    "\n",
    "\n",
    "possible_design_ways(towels_input_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "racetrack_txt = open(\"inputs/20.txt\").read()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1438"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_race_cheats(racetrack_txt):\n",
    "    grid = np.array(list(map(list, racetrack_txt.split())))\n",
    "    max_dist = np.iinfo(int).max\n",
    "    dist = np.full(grid.shape, max_dist, dtype=int)\n",
    "\n",
    "    start_pos = np.argwhere(grid == \"S\")[0]\n",
    "    dist[tuple(start_pos)] = 0\n",
    "    end_pos = np.argwhere(grid == \"E\")[0]\n",
    "    curr_pos = start_pos\n",
    "    while (curr_pos != end_pos).any():\n",
    "        for direction in Direction:\n",
    "            next_pos = curr_pos + get_dx(direction)\n",
    "            if grid[tuple(next_pos)] != \"#\" and dist[tuple(next_pos)] == max_dist:\n",
    "                dist[tuple(next_pos)] = dist[tuple(curr_pos)] + 1\n",
    "                curr_pos = next_pos\n",
    "\n",
    "    saving_counts = defaultdict(int)\n",
    "    for i in range(1, grid.shape[0] - 1):\n",
    "        for j in range(1, grid.shape[1] - 1):\n",
    "            pos = np.array([i, j])\n",
    "            nearby_dists = [curr_dist for direction in Direction if (curr_dist := dist[tuple(pos + get_dx(direction))]) != max_dist]\n",
    "            for dist1, dist2 in combinations(sorted(nearby_dists), 2):\n",
    "                saving_counts[dist2 - dist1 - 2] += 1\n",
    "\n",
    "    return sum(count for saving, count in saving_counts.items() if saving >= 100)\n",
    "\n",
    "\n",
    "find_race_cheats(racetrack_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026446"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_longer_race_cheats(racetrack_txt, n_picoseconds=20):\n",
    "    grid = np.array(list(map(list, racetrack_txt.split())))\n",
    "    max_dist = np.iinfo(int).max\n",
    "    dist = np.full(grid.shape, max_dist, dtype=int)\n",
    "\n",
    "    start_pos = np.argwhere(grid == \"S\")[0]\n",
    "    dist[tuple(start_pos)] = 0\n",
    "    end_pos = np.argwhere(grid == \"E\")[0]\n",
    "    curr_pos = start_pos\n",
    "    while (curr_pos != end_pos).any():\n",
    "        for direction in Direction:\n",
    "            next_pos = curr_pos + get_dx(direction)\n",
    "            if grid[tuple(next_pos)] != \"#\" and dist[tuple(next_pos)] == max_dist:\n",
    "                dist[tuple(next_pos)] = dist[tuple(curr_pos)] + 1\n",
    "                curr_pos = next_pos\n",
    "\n",
    "    saving_counts = defaultdict(int)\n",
    "    for i in range(1, grid.shape[0] - 1):\n",
    "        for j in range(1, grid.shape[1] - 1):\n",
    "            curr_dist = dist[i, j]\n",
    "            if curr_dist == max_dist:\n",
    "                continue\n",
    "            for d_i in range(max(-n_picoseconds, 1 - i), min(n_picoseconds + 1, grid.shape[0] - 1 - i)):\n",
    "                for d_j in range(max(-n_picoseconds + abs(d_i), 1 - j), min(n_picoseconds - abs(d_i) + 1, grid.shape[1] - 1 - j)):\n",
    "                    next_dist = dist[i + d_i, j + d_j]\n",
    "                    if next_dist != max_dist:\n",
    "                        saving_counts[next_dist - curr_dist - abs(d_i) - abs(d_j)] += 1\n",
    "    return sum(count for saving, count in saving_counts.items() if saving >= 100)\n",
    "\n",
    "\n",
    "find_longer_race_cheats(racetrack_txt, n_picoseconds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_door_codes = \"\"\"\\\n",
    "029A\n",
    "980A\n",
    "179A\n",
    "456A\n",
    "379A\"\"\".split(\"\\n\")\n",
    "door_codes = open(\"inputs/21.txt\").read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint64(219366)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def directions(single_diff):\n",
    "    if single_diff[0] < 0:\n",
    "        return \"^\" * abs(single_diff[0])\n",
    "    elif single_diff[0] > 0:\n",
    "        return \"v\" * single_diff[0]\n",
    "    elif single_diff[1] < 0:\n",
    "        return \"<\" * abs(single_diff[1])\n",
    "    return \">\" * single_diff[1]\n",
    "\n",
    "\n",
    "numeric_positions = {\n",
    "    \"0\": np.array([3, 1]),\n",
    "    \"A\": np.array([3, 2]),\n",
    "    **{str(i): np.array([2 - ((i - 1) // 3), (i - 1) % 3]) for i in range(1, 10)},\n",
    "}\n",
    "\n",
    "\n",
    "directional_positions = {\n",
    "    \"<\": np.array([1, 0]),\n",
    "    \"^\": np.array([0, 1]),\n",
    "    \">\": np.array([1, 2]),\n",
    "    \"v\": np.array([1, 1]),\n",
    "    \"A\": np.array([0, 2]),\n",
    "}\n",
    "\n",
    "\n",
    "def get_route_list(start_pos, end_pos, gap_pos):\n",
    "    diff = end_pos - start_pos\n",
    "    route_list = []\n",
    "    if np.count_nonzero(diff) == 0:\n",
    "        route_list.append(\"A\")\n",
    "    elif np.count_nonzero(diff) == 1:\n",
    "        route_list.append(directions(end_pos - start_pos) + \"A\")\n",
    "    else:\n",
    "        for p1, p2 in ((start_pos, end_pos), (end_pos, start_pos)):\n",
    "            midway_pos = np.array([p1[0], p2[1]])\n",
    "            if (midway_pos == gap_pos).all():\n",
    "                continue\n",
    "            route_list.append(directions(midway_pos - start_pos) + directions(end_pos - midway_pos) + \"A\")\n",
    "    return route_list\n",
    "\n",
    "\n",
    "def possible_numeric_routes(curr_val, next_val):\n",
    "    return get_route_list(numeric_positions[curr_val], numeric_positions[next_val], np.array([3, 0]))\n",
    "\n",
    "\n",
    "def possible_directional_routes(curr_val, next_val):\n",
    "    return get_route_list(directional_positions[curr_val], directional_positions[next_val], np.array([0, 0]))\n",
    "\n",
    "\n",
    "def complexity_sum(door_codes, n_robots):\n",
    "    directional_keys = \"<^>vA\"\n",
    "    dp = np.zeros((n_robots + 1, len(directional_keys), len(directional_keys)), dtype=np.uint64)\n",
    "    dp[0] = 1\n",
    "\n",
    "    def shortest_robot_seq_length(sequence, depth):\n",
    "        key_indices = np.array([directional_keys.index(key) for key in (\"A\" + sequence)])\n",
    "        return np.sum(dp[depth - 1, key_indices[:-1], key_indices[1:]])\n",
    "\n",
    "    for r in range(1, n_robots + 1):\n",
    "        for i1, key1 in enumerate(directional_keys):\n",
    "            for i2, key2 in enumerate(directional_keys):\n",
    "                dp[r, i1, i2] = min(shortest_robot_seq_length(route, r) for route in possible_directional_routes(key1, key2))\n",
    "\n",
    "    complexity = 0\n",
    "    for door_code in door_codes:\n",
    "        length = 0\n",
    "        for curr_val, next_val in zip(\"A\" + door_code, door_code):\n",
    "            route_list = possible_numeric_routes(curr_val, next_val)\n",
    "            length += min(shortest_robot_seq_length(route, depth=n_robots) for route in route_list)\n",
    "        complexity += int(door_code[:-1]) * length\n",
    "    return complexity\n",
    "\n",
    "\n",
    "complexity_sum(door_codes, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint64(271631192020464)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_sum(door_codes, n_robots=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_numbers_txt = open(\"inputs/22.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14476723788"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evolve_number(number):\n",
    "    number = (number ^ (number << 6)) % (2**24)\n",
    "    number = (number ^ (number >> 5)) % (2**24)\n",
    "    number = (number ^ (number << 11)) % (2**24)\n",
    "    return number\n",
    "\n",
    "\n",
    "def secret_number_sum(initial_numbers_txt):\n",
    "    sum = 0\n",
    "    initial_numbers = list(map(int, initial_numbers_txt.split()))\n",
    "    for initial_number in initial_numbers:\n",
    "        number = initial_number\n",
    "        for _ in range(2000):\n",
    "            number = evolve_number(number)\n",
    "        sum += number\n",
    "\n",
    "    return sum\n",
    "\n",
    "\n",
    "secret_number_sum(secret_numbers_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1630)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_bananas(initial_numbers_txt):\n",
    "    initial_numbers = list(map(int, initial_numbers_txt.split()))\n",
    "    total_bananas_per_change = np.zeros((19, 19, 19, 19), dtype=int)\n",
    "    for initial_number in initial_numbers:\n",
    "        seq_found = np.zeros(total_bananas_per_change.shape, dtype=bool)\n",
    "        numbers = np.empty(2001, dtype=int)\n",
    "        numbers[0] = initial_number\n",
    "        for i in range(1, 2001):\n",
    "            numbers[i] = evolve_number(numbers[i - 1])\n",
    "\n",
    "        numbers = numbers % 10\n",
    "        diffs = np.diff(numbers)\n",
    "        for i in range(4, 2001):\n",
    "            idcs = tuple(diffs[i - 4 : i])\n",
    "            if not seq_found[idcs]:\n",
    "                seq_found[idcs] = True\n",
    "                total_bananas_per_change[idcs] += numbers[i]\n",
    "    return total_bananas_per_change.max()\n",
    "\n",
    "\n",
    "max_bananas(secret_numbers_txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_txt = open(\"inputs/23.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1314"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_lan_triplets(network_txt):\n",
    "    adj_list = defaultdict(set)\n",
    "    for line in network_txt.split():\n",
    "        c1, c2 = line.split(\"-\")\n",
    "        adj_list[c1].add(c2)\n",
    "        adj_list[c2].add(c1)\n",
    "\n",
    "    n_triplets = 0\n",
    "    for c1, nbs in adj_list.items():\n",
    "        if c1[0] != \"t\":\n",
    "            continue\n",
    "        for c2, c3 in combinations(nbs, 2):\n",
    "            if c3 in adj_list[c2]:\n",
    "                if (c2[0] != \"t\" or c1 < c2) and (c3[0] != \"t\" or c1 < c3):\n",
    "                    n_triplets += 1\n",
    "\n",
    "    return n_triplets\n",
    "\n",
    "\n",
    "find_lan_triplets(network_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bg,bu,ce,ga,hw,jw,nf,nt,ox,tj,uu,vk,wp'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections.abc import Hashable\n",
    "\n",
    "\n",
    "def maximum_clique(adj_list: dict[Hashable, set[Hashable]]):\n",
    "    maximal_cliques = []\n",
    "\n",
    "    def bron_kerbosch(R, P, X):\n",
    "        if not P and not X:\n",
    "            maximal_cliques.append(R)\n",
    "        while P:\n",
    "            v = next(iter(P))\n",
    "            bron_kerbosch(R | {v}, P & adj_list[v], X & adj_list[v])\n",
    "            P.remove(v)\n",
    "            X.add(v)\n",
    "\n",
    "    bron_kerbosch(set(), set(adj_list), set())\n",
    "    return max(maximal_cliques, key=len)\n",
    "\n",
    "\n",
    "def find_lan_party(network_txt):\n",
    "    adj_list = defaultdict(set)\n",
    "    for line in network_txt.split():\n",
    "        c1, c2 = line.split(\"-\")\n",
    "        adj_list[c1].add(c2)\n",
    "        adj_list[c2].add(c1)\n",
    "\n",
    "    return \",\".join(sorted(maximum_clique(adj_list)))\n",
    "\n",
    "\n",
    "find_lan_party(network_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gates_input_txt = open(\"inputs/24.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51745744348272"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_gates(gates_input_txt):\n",
    "    initial_values_lines, gates_lines = (txt.split(\"\\n\") for txt in gates_input_txt.split(\"\\n\\n\"))\n",
    "    gates_lines = gates_lines[:-1]\n",
    "    wire_values = {wire: int(value) for wire, value in map(lambda line: line.split(\": \"), initial_values_lines)}\n",
    "\n",
    "    gate_mapping = {\n",
    "        \"AND\": lambda left, right: left and right,\n",
    "        \"OR\": lambda left, right: left or right,\n",
    "        \"XOR\": lambda left, right: left ^ right,\n",
    "    }\n",
    "    gate_ops = {\n",
    "        output: (input1, gate_mapping[gate], input2) for input1, gate, input2, _, output in map(lambda line: line.split(), gates_lines)\n",
    "    }\n",
    "\n",
    "    def obtain_gate_value(output):\n",
    "        if output not in wire_values:\n",
    "            input1, gate_op, input2 = gate_ops[output]\n",
    "            val1 = obtain_gate_value(input1)\n",
    "            val2 = obtain_gate_value(input2)\n",
    "            wire_values[output] = gate_op(val1, val2)\n",
    "\n",
    "        return wire_values[output]\n",
    "\n",
    "    output_wires = sorted(filter(lambda wire: wire[2].isdigit(), gate_ops.keys()))\n",
    "    return sum(obtain_gate_value(output_wire) << i for i, output_wire in enumerate(output_wires))\n",
    "\n",
    "\n",
    "simulate_gates(gates_input_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== z00 ======\n",
      "y00 XOR x00 z00\n",
      "====== z01 ======\n",
      "y00 AND x00 rjr\n",
      "x01 XOR y01 sgt\n",
      "rjr XOR sgt z01\n",
      "====== z02 ======\n",
      "x01 AND y01 hqg\n",
      "rjr AND sgt cff\n",
      "hqg OR cff fkm\n",
      "y02 XOR x02 hvb\n",
      "fkm XOR hvb z02\n",
      "====== z03 ======\n",
      "fkm AND hvb hnv\n",
      "x02 AND y02 rbm\n",
      "hnv OR rbm bdp\n",
      "y03 XOR x03 thv\n",
      "bdp XOR thv z03\n",
      "====== z04 ======\n",
      "x04 XOR y04 stt\n",
      "y03 AND x03 bfs\n",
      "thv AND bdp rvq\n",
      "bfs OR rvq cmh\n",
      "stt XOR cmh z04\n",
      "====== z05 ======\n",
      "stt AND cmh mwj\n",
      "x04 AND y04 pmq\n",
      "mwj OR pmq ngj\n",
      "y05 XOR x05 pqj\n",
      "ngj XOR pqj z05\n",
      "====== z06 ======\n",
      "y05 AND x05 rkt\n",
      "ngj AND pqj ckj\n",
      "rkt OR ckj wts\n",
      "x06 XOR y06 vrh\n",
      "wts XOR vrh z06\n",
      "====== z07 ======\n",
      "vrh AND wts mcs\n",
      "y06 AND x06 jwh\n",
      "mcs OR jwh swp\n",
      "x07 XOR y07 fcs\n",
      "swp XOR fcs z07\n",
      "====== z08 ======\n",
      "fcs AND swp jdb\n",
      "y07 AND x07 btb\n",
      "jdb OR btb kpt\n",
      "x08 XOR y08 prr\n",
      "kpt XOR prr z08\n",
      "====== z09 ======\n",
      "y09 XOR x09 kmk\n",
      "x08 AND y08 mkj\n",
      "kpt AND prr rdt\n",
      "mkj OR rdt qvw\n",
      "kmk XOR qvw z09\n",
      "====== z10 ======\n",
      "y10 XOR x10 wvn\n",
      "qvw AND kmk qfq\n",
      "y09 AND x09 spq\n",
      "qfq OR spq trw\n",
      "wvn XOR trw z10\n",
      "====== z11 ======\n",
      "x10 AND y10 vrj\n",
      "trw AND wvn cvp\n",
      "vrj OR cvp nvc\n",
      "x11 XOR y11 tgd\n",
      "nvc XOR tgd z11\n",
      "====== z12 ======\n",
      "y11 AND x11 tst\n",
      "tgd AND nvc jnn\n",
      "tst OR jnn stg\n",
      "y12 XOR x12 trp\n",
      "stg XOR trp z12\n",
      "====== z13 ======\n",
      "x13 XOR y13 hnt\n",
      "stg AND trp fmk\n",
      "y12 AND x12 dbr\n",
      "fmk OR dbr wnj\n",
      "hnt XOR wnj z13\n",
      "====== z14 ======\n",
      "x13 AND y13 mkh\n",
      "wnj AND hnt qdw\n",
      "mkh OR qdw vsd\n",
      "y14 XOR x14 nmb\n",
      "vsd XOR nmb z14\n",
      "====== z15 ======\n",
      "y15 XOR x15 nhg\n",
      "vsd AND nmb csh\n",
      "x14 AND y14 smm\n",
      "csh OR smm prp\n",
      "nhg XOR prp z15\n",
      "====== z16 ======\n",
      "prp AND nhg ckp\n",
      "y15 AND x15 wbt\n",
      "ckp OR wbt hdg\n",
      "y16 XOR x16 qpj\n",
      "hdg XOR qpj z16\n",
      "====== z17 ======\n",
      "y17 XOR x17 pbr\n",
      "hdg AND qpj dhg\n",
      "y16 AND x16 bpn\n",
      "dhg OR bpn pch\n",
      "pbr XOR pch z17\n",
      "====== z18 ======\n",
      "pbr AND pch rrb\n",
      "y17 AND x17 dpj\n",
      "rrb OR dpj mdg\n",
      "x18 XOR y18 jss\n",
      "mdg XOR jss z18\n",
      "====== z19 ======\n",
      "jss AND mdg hmt\n",
      "y18 AND x18 jcr\n",
      "hmt OR jcr pfb\n",
      "x19 XOR y19 jmh\n",
      "pfb XOR jmh z19\n",
      "====== z20 ======\n",
      "jmh AND pfb nts\n",
      "x19 AND y19 wrc\n",
      "nts OR wrc scv\n",
      "y20 XOR x20 mbp\n",
      "scv XOR mbp z20\n",
      "====== z21 ======\n",
      "mbp AND scv tpm\n",
      "y20 AND x20 jqj\n",
      "tpm OR jqj pdc\n",
      "y21 XOR x21 gbs\n",
      "pdc XOR gbs z21\n",
      "====== z22 ======\n",
      "y22 XOR x22 svq\n",
      "gbs AND pdc fff\n",
      "x21 AND y21 pgr\n",
      "fff OR pgr tmk\n",
      "svq XOR tmk z22\n",
      "====== z23 ======\n",
      "svq AND tmk btw\n",
      "y22 AND x22 gsg\n",
      "btw OR gsg kvp\n",
      "x23 XOR y23 pcv\n",
      "kvp XOR pcv z23\n",
      "====== z24 ======\n",
      "y23 AND x23 npr\n",
      "kvp AND pcv jnh\n",
      "npr OR jnh fhw\n",
      "x24 XOR y24 nkc\n",
      "fhw XOR nkc z24\n",
      "====== z25 ======\n",
      "y25 XOR x25 tsw\n",
      "nkc AND fhw ngb\n",
      "y24 AND x24 krb\n",
      "ngb OR krb vst\n",
      "tsw XOR vst z25\n",
      "====== z26 ======\n",
      "y25 AND x25 hcp\n",
      "vst AND tsw jgn\n",
      "hcp OR jgn cbj\n",
      "y26 XOR x26 fnf\n",
      "cbj XOR fnf z26\n",
      "====== z27 ======\n",
      "x27 XOR y27 ntr\n",
      "y26 AND x26 jcb\n",
      "cbj AND fnf pnj\n",
      "jcb OR pnj gcc\n",
      "ntr XOR gcc z27\n",
      "====== z28 ======\n",
      "y28 XOR x28 mkq\n",
      "x27 AND y27 vgg\n",
      "gcc AND ntr pph\n",
      "vgg OR pph bfq\n",
      "mkq XOR bfq z28\n",
      "====== z29 ======\n",
      "x28 AND y28 qfw\n",
      "bfq AND mkq pms\n",
      "qfw OR pms mcb\n",
      "y29 XOR x29 ftt\n",
      "mcb XOR ftt z29\n",
      "====== z30 ======\n",
      "y30 XOR x30 qrt\n",
      "ftt AND mcb wmd\n",
      "y29 AND x29 bsk\n",
      "wmd OR bsk hhd\n",
      "qrt XOR hhd z30\n",
      "====== z31 ======\n",
      "x31 XOR y31 fqh\n",
      "y30 AND x30 nww\n",
      "hhd AND qrt spj\n",
      "nww OR spj ctc\n",
      "fqh XOR ctc z31\n",
      "====== z32 ======\n",
      "y31 AND x31 hkh\n",
      "fqh AND ctc rjt\n",
      "hkh OR rjt qhp\n",
      "y32 XOR x32 vbw\n",
      "qhp XOR vbw z32\n",
      "====== z33 ======\n",
      "y33 XOR x33 rqf\n",
      "x32 AND y32 nwj\n",
      "vbw AND qhp smg\n",
      "nwj OR smg grt\n",
      "rqf XOR grt z33\n",
      "====== z34 ======\n",
      "grt AND rqf hbq\n",
      "x33 AND y33 twj\n",
      "hbq OR twj hkt\n",
      "x34 XOR y34 qrn\n",
      "hkt XOR qrn z34\n",
      "====== z35 ======\n",
      "hkt AND qrn qdd\n",
      "y34 AND x34 gck\n",
      "qdd OR gck rfw\n",
      "x35 XOR y35 qnw\n",
      "rfw XOR qnw z35\n",
      "====== z36 ======\n",
      "y35 AND x35 kps\n",
      "rfw AND qnw wvq\n",
      "kps OR wvq wgm\n",
      "y36 XOR x36 rfv\n",
      "wgm XOR rfv z36\n",
      "====== z37 ======\n",
      "y37 XOR x37 ngq\n",
      "rfv AND wgm jwd\n",
      "x36 AND y36 ssg\n",
      "jwd OR ssg cgm\n",
      "ngq XOR cgm z37\n",
      "====== z38 ======\n",
      "y38 XOR x38 crj\n",
      "x37 AND y37 kqm\n",
      "ngq AND cgm vdw\n",
      "kqm OR vdw vvr\n",
      "crj XOR vvr z38\n",
      "====== z39 ======\n",
      "vvr AND crj mdm\n",
      "y38 AND x38 cwb\n",
      "mdm OR cwb hsf\n",
      "x39 XOR y39 bng\n",
      "hsf XOR bng z39\n",
      "====== z40 ======\n",
      "bng AND hsf tkf\n",
      "y39 AND x39 fjp\n",
      "tkf OR fjp vbm\n",
      "x40 XOR y40 qqb\n",
      "vbm XOR qqb z40\n",
      "====== z41 ======\n",
      "x41 XOR y41 dsb\n",
      "y40 AND x40 dnr\n",
      "vbm AND qqb nhq\n",
      "dnr OR nhq rgt\n",
      "dsb XOR rgt z41\n",
      "====== z42 ======\n",
      "y41 AND x41 hrh\n",
      "rgt AND dsb vtn\n",
      "hrh OR vtn swn\n",
      "y42 XOR x42 jkm\n",
      "swn XOR jkm z42\n",
      "====== z43 ======\n",
      "y43 XOR x43 jtb\n",
      "swn AND jkm tbg\n",
      "x42 AND y42 jfp\n",
      "tbg OR jfp bkf\n",
      "jtb XOR bkf z43\n",
      "====== z44 ======\n",
      "x43 AND y43 dcp\n",
      "jtb AND bkf dmk\n",
      "dcp OR dmk tfj\n",
      "x44 XOR y44 bcg\n",
      "tfj XOR bcg z44\n",
      "====== z45 ======\n",
      "x44 AND y44 fnd\n",
      "tfj AND bcg scp\n",
      "fnd OR scp z45\n"
     ]
    }
   ],
   "source": [
    "def find_gate_errors(gates_input_txt):\n",
    "    initial_values_lines, gates_lines = (txt.split(\"\\n\") for txt in gates_input_txt.split(\"\\n\\n\"))\n",
    "    gates_lines = gates_lines[:-1]\n",
    "    wire_values = {wire: int(value) for wire, value in map(lambda line: line.split(\": \"), initial_values_lines)}\n",
    "\n",
    "    gate_mapping = {\n",
    "        \"AND\": lambda left, right: left and right,\n",
    "        \"OR\": lambda left, right: left or right,\n",
    "        \"XOR\": lambda left, right: left ^ right,\n",
    "    }\n",
    "    gate_ops = {output: (input1, gate, input2) for input1, gate, input2, _, output in map(lambda line: line.split(), gates_lines)}\n",
    "\n",
    "    for g1, g2 in [(\"z31\", \"hkh\"), (\"z27\", \"bfq\"), (\"bng\", \"fjp\"), (\"hmt\", \"z18\")]:\n",
    "        val1 = gate_ops[g1]\n",
    "        val2 = gate_ops[g2]\n",
    "\n",
    "        gate_ops[g2] = val1\n",
    "        gate_ops[g1] = val2\n",
    "\n",
    "    def obtain_gate_value(output):\n",
    "        if output not in wire_values:\n",
    "            input1, gate_op, input2 = gate_ops[output]\n",
    "            val1 = obtain_gate_value(input1)\n",
    "            val2 = obtain_gate_value(input2)\n",
    "            wire_values[output] = gate_mapping[gate_op](val1, val2)\n",
    "            print(input1, gate_op, input2, output)\n",
    "\n",
    "        return wire_values[output]\n",
    "\n",
    "    output_wires = sorted(filter(lambda wire: wire[2].isdigit(), gate_ops.keys()))\n",
    "    for output_wire in output_wires:\n",
    "        print(f\"====== {output_wire} ======\")\n",
    "        obtain_gate_value(output_wire)\n",
    "\n",
    "\n",
    "find_gate_errors(gates_input_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bfq,bng,fjp,hkh,hmt,z18,z27,z31'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(sorted(wire for wires in [(\"z31\", \"hkh\"), (\"z27\", \"bfq\"), (\"bng\", \"fjp\"), (\"hmt\", \"z18\")] for wire in wires))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_lock_txt = open(\"inputs/25.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2618)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_key_lock(grid_txt):\n",
    "    sizes = np.sum(np.array(list(map(list, grid_txt.split()))) == \"#\", axis=0) - 1\n",
    "    is_key = grid_txt[0] == \".\"\n",
    "    return is_key, sizes\n",
    "\n",
    "\n",
    "def key_lock_combinations(key_lock_txt):\n",
    "    keys = []\n",
    "    locks = []\n",
    "    for is_key, sizes in map(analyze_key_lock, key_lock_txt[:-1].split(\"\\n\\n\")):\n",
    "        if is_key:\n",
    "            keys.append(sizes)\n",
    "        else:\n",
    "            locks.append(sizes)\n",
    "\n",
    "    return sum(((key + lock) < 6).all() for key in keys for lock in locks)\n",
    "\n",
    "\n",
    "key_lock_combinations(key_lock_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
