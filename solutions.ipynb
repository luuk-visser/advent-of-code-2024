{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Direction(Enum):\n",
    "    UP = 0\n",
    "    RIGHT = 1\n",
    "    DOWN = 2\n",
    "    LEFT = 3\n",
    "\n",
    "\n",
    "def rotate_right(direction):\n",
    "    return Direction((direction.value + 1) % 4)\n",
    "\n",
    "\n",
    "def rotate_left(direction):\n",
    "    return Direction((direction.value - 1) % 4)\n",
    "\n",
    "\n",
    "def is_opposite(d1, d2):\n",
    "    return rotate_right(rotate_right(d1)) == d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2000468)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"inputs/1.txt\", dtype=int)\n",
    "sorted_data = np.sort(data, axis=0)\n",
    "np.abs(sorted_data[:, 0] - sorted_data[:, 1]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18567089.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.concat(\n",
    "    [\n",
    "        pd.Series(sorted_data[:, 0]).value_counts().rename(\"0\"),\n",
    "        pd.Series(sorted_data[:, 1]).value_counts().rename(\"1\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").dropna()\n",
    "\n",
    "(counts.iloc[:, 0] * counts.iloc[:, 1] * counts.index).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = [np.fromiter(line.split(), int) for line in open(\"inputs/2.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(502)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_safe(report):\n",
    "    changes = np.diff(report)\n",
    "    signs = np.sign(changes)\n",
    "    return signs[0] != 0 and (signs == signs[0]).all() and (np.abs(changes) <= 3).all()\n",
    "\n",
    "\n",
    "sum(map(is_safe, reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def are_valid_changes(changes, possible_sign):\n",
    "    return (np.sign(changes) == possible_sign) & (np.abs(changes) <= 3)\n",
    "\n",
    "\n",
    "def is_safe_with_dampener(report):\n",
    "    if report.size < 3:\n",
    "        return True\n",
    "\n",
    "    changes = np.diff(report)\n",
    "    for possible_sign in [-1, 1]:\n",
    "        errors = ~are_valid_changes(changes, possible_sign)\n",
    "        n_errors = errors.sum()\n",
    "        if n_errors > 2:\n",
    "            continue\n",
    "        elif n_errors == 2:\n",
    "            idcs = np.nonzero(errors)[0]\n",
    "            if idcs[0] + 1 != idcs[1] or not are_valid_changes(changes[idcs[0]] + changes[idcs[1]], possible_sign):\n",
    "                continue\n",
    "        elif n_errors == 1:\n",
    "            idx = np.argmax(errors)\n",
    "            if (\n",
    "                idx != 0\n",
    "                and idx != changes.size - 1\n",
    "                and not are_valid_changes(changes[idx] + changes[idx + 1], possible_sign)\n",
    "                and not are_valid_changes(changes[idx - 1] + changes[idx], possible_sign)\n",
    "            ):\n",
    "                continue\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "sum(map(is_safe_with_dampener, reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = open(\"inputs/3.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180233229"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(int(a) * int(b) for a, b in re.findall(r\"mul\\(([0-9]+),([0-9]+)\\)\", memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95411583"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_with_conditionals(memory):\n",
    "    total_sum = 0\n",
    "    enabled = True\n",
    "    for a, b, do_string, dont_string in re.findall(r\"mul\\(([0-9]+),([0-9]+)\\)|(do\\(\\))|(don't\\(\\))\", memory):\n",
    "        if a:\n",
    "            if enabled:\n",
    "                total_sum += int(a) * int(b)\n",
    "        elif do_string:\n",
    "            enabled = True\n",
    "        elif dont_string:\n",
    "            enabled = False\n",
    "    return total_sum\n",
    "\n",
    "\n",
    "calc_with_conditionals(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = np.array(list(map(list, open(\"inputs/4.txt\").read().split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_xmas(text, words=(\"XMAS\", \"SAMX\")):\n",
    "    total_count = 0\n",
    "    n, m = text.shape\n",
    "\n",
    "    for view in [\n",
    "        text,\n",
    "        text.T,\n",
    "        [np.diagonal(text, offset=offset) for offset in range(-n + 1, m)],\n",
    "        [np.diagonal(np.flipud(text), offset=offset) for offset in range(-n + 1, m)],\n",
    "    ]:\n",
    "        total_count += sum(\"\".join(line).count(word) for line in view for word in words)\n",
    "\n",
    "    return total_count\n",
    "\n",
    "\n",
    "count_xmas(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1921"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_max(text):\n",
    "    total_count = 0\n",
    "    n, m = text.shape\n",
    "    for i_min in range(n - 2):\n",
    "        for j_min in range(m - 2):\n",
    "            if text[i_min + 1, j_min + 1] == \"A\":\n",
    "                i_max = i_min + 2\n",
    "                j_max = j_min + 2\n",
    "                diag_txt = text[[i_min, i_min, i_max, i_max], [j_min, j_max, j_min, j_max]]\n",
    "                if diag_txt[0] != diag_txt[3] and np.count_nonzero(diag_txt == \"S\") == 2 and np.count_nonzero(diag_txt == \"M\") == 2:\n",
    "                    total_count += 1\n",
    "    return total_count\n",
    "\n",
    "\n",
    "count_max(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_txt, updates_txt = open(\"inputs/5.txt\").read().split(\"\\n\\n\")\n",
    "rules = [(int(x), int(y)) for x, y in (rule.split(\"|\") for rule in rules_txt.split())]\n",
    "updates = [[int(x) for x in line.split(\",\")] for line in updates_txt.split()]\n",
    "succeeding_pages = defaultdict(set)\n",
    "for rule in rules:\n",
    "    succeeding_pages[rule[0]].add(rule[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6384\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def is_correctly_ordered(update):\n",
    "    return not any(x in succeeding_pages[y] for x, y in combinations(update, 2))\n",
    "\n",
    "\n",
    "def middle_page(update):\n",
    "    return update[(len(update) - 1) // 2]\n",
    "\n",
    "\n",
    "total_sum = sum(middle_page(update) for update in updates if is_correctly_ordered(update))\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5353"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "\n",
    "def fix_update(update):\n",
    "    update = copy(update)\n",
    "    for i, _ in enumerate(update):\n",
    "        j = i + 1\n",
    "        while j < len(update):\n",
    "            if update[i] in succeeding_pages[update[j]]:\n",
    "                update[i], update[j] = update[j], update[i]\n",
    "                j = i + 1\n",
    "            else:\n",
    "                j += 1\n",
    "    return update\n",
    "\n",
    "\n",
    "incorrect_updates = (update for update in updates if not is_correctly_ordered(update))\n",
    "sum(middle_page(fix_update(update)) for update in incorrect_updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5269"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx_vectors = np.array(\n",
    "    [\n",
    "        [-1, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [0, -1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_dx(direction):\n",
    "    return dx_vectors[direction.value]\n",
    "\n",
    "\n",
    "def get_direction(symbol):\n",
    "    return Direction(\"^>V<\".index(symbol))\n",
    "\n",
    "\n",
    "class Grid:\n",
    "    def __init__(self, grid_txt):\n",
    "        self.grid = np.array(list(map(list, grid_txt.split())))\n",
    "        self.n, self.m = self.grid.shape\n",
    "        self.reset_history()\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.history = np.zeros((*self.grid.shape, 4), bool)\n",
    "\n",
    "    def get(self, pos):\n",
    "        return self.grid[tuple(pos)]\n",
    "\n",
    "    def move_forward(self, pos, direction):\n",
    "        return pos + get_dx(direction)\n",
    "\n",
    "    def next_state(self, pos, direction):\n",
    "        new_pos = self.move_forward(pos, direction)\n",
    "        if self.out_of_bounds(new_pos):\n",
    "            return new_pos, direction, True\n",
    "        if self.get(new_pos) == \"#\":\n",
    "            direction = rotate_right(direction)\n",
    "        else:\n",
    "            pos = new_pos\n",
    "        return pos, direction, False\n",
    "\n",
    "    def find_guard_position(self):\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                if self.grid[i, j] != \".\" and self.grid[i, j] != \"#\":\n",
    "                    return i, j\n",
    "        return -1, -1\n",
    "\n",
    "    def out_of_bounds(self, pos):\n",
    "        return pos[0] < 0 or pos[0] >= self.n or pos[1] < 0 or pos[1] >= self.m\n",
    "\n",
    "    def mark_visited(self, pos, direction):\n",
    "        self.history[pos[0], pos[1], direction.value] = True\n",
    "\n",
    "    def already_visited(self, pos, direction):\n",
    "        return self.history[pos[0], pos[1], direction.value]\n",
    "\n",
    "    def count_visited(self):\n",
    "        return np.count_nonzero(self.history.any(axis=2))\n",
    "\n",
    "\n",
    "def distinct_positions(grid_txt):\n",
    "    grid = Grid(grid_txt)\n",
    "    pos = np.array(grid.find_guard_position())\n",
    "    direction = get_direction(grid.get(pos))\n",
    "    out_of_bounds = False\n",
    "\n",
    "    while not out_of_bounds:\n",
    "        grid.mark_visited(pos, direction)\n",
    "        pos, direction, out_of_bounds = grid.next_state(pos, direction)\n",
    "\n",
    "    return grid.count_visited()\n",
    "\n",
    "\n",
    "grid_txt = open(\"inputs/6.txt\").read()\n",
    "distinct_positions(grid_txt)  # 5269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m             grid\u001b[38;5;241m.\u001b[39mgrid[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m n_looping_obstacles\n\u001b[1;32m---> 29\u001b[0m \u001b[43mlooping_obstacles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_txt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 1957\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 18\u001b[0m, in \u001b[0;36mlooping_obstacles\u001b[1;34m(grid_txt)\u001b[0m\n\u001b[0;32m     16\u001b[0m out_of_bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_of_bounds:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malready_visited\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     19\u001b[0m         n_looping_obstacles \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 57\u001b[0m, in \u001b[0;36mGrid.already_visited\u001b[1;34m(self, pos, direction)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmark_visited\u001b[39m(\u001b[38;5;28mself\u001b[39m, pos, direction):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[pos[\u001b[38;5;241m0\u001b[39m], pos[\u001b[38;5;241m1\u001b[39m], direction\u001b[38;5;241m.\u001b[39mvalue] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21malready_visited\u001b[39m(\u001b[38;5;28mself\u001b[39m, pos, direction):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[pos[\u001b[38;5;241m0\u001b[39m], pos[\u001b[38;5;241m1\u001b[39m], direction\u001b[38;5;241m.\u001b[39mvalue]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_visited\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def looping_obstacles(grid_txt):\n",
    "    n_looping_obstacles = 0\n",
    "    grid = Grid(grid_txt)\n",
    "    initial_pos = np.array(grid.find_guard_position())\n",
    "    initial_direction = get_direction(grid.get(initial_pos))\n",
    "\n",
    "    for i in range(grid.n):\n",
    "        for j in range(grid.m):\n",
    "            if grid.grid[i, j] != \".\":\n",
    "                continue\n",
    "\n",
    "            grid.reset_history()\n",
    "            grid.grid[i, j] = \"#\"\n",
    "            pos = initial_pos\n",
    "            direction = initial_direction\n",
    "            out_of_bounds = False\n",
    "            while not out_of_bounds:\n",
    "                if grid.already_visited(pos, direction):\n",
    "                    n_looping_obstacles += 1\n",
    "                    break\n",
    "                grid.mark_visited(pos, direction)\n",
    "                pos, direction, out_of_bounds = grid.next_state(pos, direction)\n",
    "\n",
    "            grid.grid[i, j] = \".\"\n",
    "\n",
    "    return n_looping_obstacles\n",
    "\n",
    "\n",
    "looping_obstacles(grid_txt)  # 1957\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equations(equations_txt):\n",
    "    return [\n",
    "        (int(test), np.fromstring(numbers, int, sep=\" \"))\n",
    "        for test, numbers in (equation.split(\": \") for equation in equations_txt.splitlines())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20281182715321"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_combinations(test, numbers, current_value=0):\n",
    "    if numbers.size == 0:\n",
    "        return test == current_value\n",
    "    if current_value > test:\n",
    "        return False\n",
    "    return check_combinations(test, numbers[1:], current_value=current_value + numbers[0]) or check_combinations(\n",
    "        test, numbers[1:], current_value=current_value * numbers[0]\n",
    "    )\n",
    "\n",
    "\n",
    "equations_txt = open(\"inputs/7.txt\").read()\n",
    "equations = get_equations(equations_txt)\n",
    "\n",
    "sum(test for test, numbers in equations if check_combinations(test, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_combinations_with_concat(test, numbers, current_value=0):\n",
    "    if numbers.size == 0:\n",
    "        return test == current_value\n",
    "    if current_value > test:\n",
    "        return False\n",
    "    return (\n",
    "        check_combinations_with_concat(test, numbers[1:], current_value=current_value + numbers[0])\n",
    "        or check_combinations_with_concat(test, numbers[1:], current_value=current_value * numbers[0])\n",
    "        or check_combinations_with_concat(test, numbers[1:], current_value=int(str(current_value) + str(numbers[0])))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159490400628354"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test for test, numbers in equations if check_combinations_with_concat(test, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_antenna_locs(antenna_map):\n",
    "    locs = defaultdict(list)\n",
    "    for i, line in enumerate(antenna_map):\n",
    "        for j, symbol in enumerate(line):\n",
    "            if symbol != \".\":\n",
    "                locs[symbol].append(np.array([i, j]))\n",
    "    return locs\n",
    "\n",
    "\n",
    "antenna_map_txt = open(\"inputs/8.txt\").read()\n",
    "\n",
    "antenna_map_example_txt = \"\"\"\\\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def within_bounds(coords, max_coords):\n",
    "    return (coords >= 0).all() and (coords < max_coords).all()\n",
    "\n",
    "\n",
    "def get_n_antinodes(antenna_map_txt):\n",
    "    antenna_map = antenna_map_txt.splitlines()\n",
    "    antenna_locs = get_antenna_locs(antenna_map)\n",
    "\n",
    "    antinode_locs = set()\n",
    "    max_coords = np.array([len(antenna_map), len(antenna_map[0])])\n",
    "    for freq_locs in antenna_locs.values():\n",
    "        for c1, c2 in combinations(freq_locs, 2):\n",
    "            diff = c2 - c1\n",
    "            for antinode in (c1 - diff, c2 + diff):\n",
    "                if within_bounds(antinode, max_coords):\n",
    "                    antinode_locs.add(tuple(antinode))\n",
    "\n",
    "    return len(antinode_locs)\n",
    "\n",
    "\n",
    "get_n_antinodes(antenna_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_resonant_antinodes(antenna_map_txt):\n",
    "    antenna_map = antenna_map_txt.splitlines()\n",
    "    antenna_locs = get_antenna_locs(antenna_map)\n",
    "\n",
    "    antinode_locs = set()\n",
    "    max_coords = np.array([len(antenna_map), len(antenna_map[0])])\n",
    "\n",
    "    for freq_locs in antenna_locs.values():\n",
    "        for c1, c2 in combinations(freq_locs, 2):\n",
    "            for pos, offset in ((c1.copy(), c1 - c2), (c2.copy(), c2 - c1)):\n",
    "                while within_bounds(pos, max_coords):\n",
    "                    antinode_locs.add(tuple(pos))\n",
    "                    pos += offset\n",
    "    return len(antinode_locs)\n",
    "\n",
    "\n",
    "get_n_resonant_antinodes(antenna_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_map_txt = open(\"inputs/9.txt\").read()[:-1]\n",
    "\n",
    "\n",
    "def position_sum(curr_pos, new_pos):\n",
    "    return (new_pos + curr_pos - 1) * (new_pos - curr_pos) // 2\n",
    "\n",
    "\n",
    "def update_checksum_and_position(checksum, curr_pos, digit, digit_idx):\n",
    "    new_pos = curr_pos + digit\n",
    "    checksum += digit_idx * position_sum(curr_pos, new_pos)\n",
    "    return checksum, new_pos\n",
    "\n",
    "\n",
    "def reordered_checksum(disk_map_txt):\n",
    "    digits = list(map(int, disk_map_txt[::2]))\n",
    "    spaces = list(map(int, disk_map_txt[1::2]))\n",
    "    checksum = 0\n",
    "    curr_pos = 0\n",
    "    end_idx = len(digits) - 1\n",
    "    for idx, _ in enumerate(digits):\n",
    "        checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, digits[idx], idx)\n",
    "\n",
    "        if end_idx <= idx:\n",
    "            break\n",
    "\n",
    "        while end_idx > idx and spaces[idx] > 0:\n",
    "            filled_positions = min(digits[end_idx], spaces[idx])\n",
    "            spaces[idx] -= filled_positions\n",
    "            digits[end_idx] -= filled_positions\n",
    "            checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, filled_positions, end_idx)\n",
    "            if digits[end_idx] == 0:\n",
    "                end_idx -= 1\n",
    "\n",
    "    return checksum\n",
    "\n",
    "\n",
    "disk_map_example_txt = \"2333133121414131402\"\n",
    "reordered_checksum(disk_map_example_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6408966547049"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def defragmented_checksum(disk_map_txt):\n",
    "    digits_per_pos = [[(dig_id, int(symbol))] for dig_id, symbol in enumerate(disk_map_txt[::2])]\n",
    "    spaces = list(map(int, disk_map_txt[1::2])) + [0]\n",
    "\n",
    "    for end_idx, _ in reversed(list(enumerate(digits_per_pos))):\n",
    "        dig_id, digit = digits_per_pos[end_idx][0]\n",
    "        for space_idx, _ in enumerate(spaces):\n",
    "            if space_idx >= end_idx:\n",
    "                break\n",
    "            if spaces[space_idx] >= digit:\n",
    "                spaces[space_idx] -= digit\n",
    "                digits_per_pos[space_idx].append((dig_id, digit))\n",
    "                spaces[dig_id - 1] += digit\n",
    "                digits_per_pos[dig_id][0] = (dig_id, 0)\n",
    "                break\n",
    "\n",
    "    curr_pos = 0\n",
    "    checksum = 0\n",
    "    for idx, digit_list in enumerate(digits_per_pos):\n",
    "        for dig_id, digit in digit_list:\n",
    "            checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, digit, dig_id)\n",
    "        curr_pos += spaces[idx]\n",
    "\n",
    "    return checksum\n",
    "\n",
    "\n",
    "defragmented_checksum(disk_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_map_txt = open(\"inputs/10.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_score(topo_map_txt):\n",
    "    topo_map = np.array([list(map(int, line)) for line in topo_map_txt.splitlines()])\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= topo_map.shape[0] or j >= topo_map.shape[1]\n",
    "\n",
    "    deltas = np.array(\n",
    "        [\n",
    "            [0, 1],\n",
    "            [1, 0],\n",
    "            [0, -1],\n",
    "            [-1, 0],\n",
    "        ]\n",
    "    )\n",
    "    score = 0\n",
    "    trailheads = np.argwhere(topo_map == 0)\n",
    "    for trailhead in trailheads:\n",
    "        visited = np.zeros_like(topo_map, dtype=bool)\n",
    "        stack = [trailhead]\n",
    "        while stack:\n",
    "            top = stack.pop()\n",
    "            if visited[tuple(top)]:\n",
    "                continue\n",
    "\n",
    "            if topo_map[tuple(top)] == 9:\n",
    "                score += 1\n",
    "            visited[tuple(top)] = True\n",
    "            for delta in deltas:\n",
    "                new_pos = top + delta\n",
    "                if (\n",
    "                    not out_of_bounds(*new_pos)\n",
    "                    and not visited[tuple(new_pos)]\n",
    "                    and topo_map[tuple(new_pos)] == topo_map[tuple(top)] + 1\n",
    "                ):\n",
    "                    stack.append(new_pos)\n",
    "    return score\n",
    "\n",
    "\n",
    "map_score(topo_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1324)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_score(topo_map_txt):\n",
    "    topo_map = np.array([list(map(int, line)) for line in topo_map_txt.splitlines()])\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= topo_map.shape[0] or j >= topo_map.shape[1]\n",
    "\n",
    "    deltas = np.array(\n",
    "        [\n",
    "            [0, 1],\n",
    "            [1, 0],\n",
    "            [0, -1],\n",
    "            [-1, 0],\n",
    "        ]\n",
    "    )\n",
    "    score = 0\n",
    "    trailheads = np.argwhere(topo_map == 0)\n",
    "\n",
    "    visited = np.zeros_like(topo_map, dtype=int)\n",
    "    for pos in trailheads:\n",
    "        visited[tuple(pos)] = 1\n",
    "    new_stack = list(trailheads)\n",
    "    height = 0\n",
    "\n",
    "    while new_stack:\n",
    "        stack = new_stack\n",
    "        new_stack = []\n",
    "        for pos in stack:\n",
    "            for delta in deltas:\n",
    "                new_pos = pos + delta\n",
    "                if not out_of_bounds(*new_pos) and topo_map[tuple(new_pos)] == height + 1:\n",
    "                    if not visited[tuple(new_pos)]:\n",
    "                        new_stack.append(new_pos)\n",
    "                    visited[tuple(new_pos)] += visited[tuple(pos)]\n",
    "        height += 1\n",
    "\n",
    "    score = sum(visited[tuple(pos)] for pos in np.argwhere(topo_map == 9))\n",
    "    return score\n",
    "\n",
    "\n",
    "map_score(topo_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190865"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evolve(number):\n",
    "    if number == 0:\n",
    "        return [1]\n",
    "\n",
    "    digits = str(number)\n",
    "    n_digits = len(digits)\n",
    "    if n_digits % 2 == 0:\n",
    "        return [int(digits[: n_digits // 2]), int(digits[n_digits // 2 :])]\n",
    "\n",
    "    return [number * 2024]\n",
    "\n",
    "\n",
    "def get_n_stones(stones_txt, n_blinks=25):\n",
    "    stone_counts = dict(Counter(map(int, stones_txt.split())))\n",
    "\n",
    "    for i in range(n_blinks):\n",
    "        next_counts = defaultdict(int)\n",
    "        for number, count in stone_counts.items():\n",
    "            for evolved_number in evolve(number):\n",
    "                next_counts[evolved_number] += count\n",
    "        stone_counts = next_counts\n",
    "    return sum(stone_counts.values())\n",
    "\n",
    "\n",
    "stones_txt = open(\"inputs/11.txt\").read()\n",
    "\n",
    "get_n_stones(stones_txt, n_blinks=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225404711855335"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_stones(stones_txt, n_blinks=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delta(coords, delta):\n",
    "    return (coords[0] + delta[0], coords[1] + delta[1])\n",
    "\n",
    "\n",
    "def fencing_price(garden_txt):\n",
    "    garden = np.array(list(map(list, garden_txt.split())))\n",
    "\n",
    "    visited = np.zeros_like(garden, dtype=bool)\n",
    "    deltas = (\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (1, 0),\n",
    "        (0, -1),\n",
    "    )\n",
    "\n",
    "    def is_connected(nb_coords, plant_type):\n",
    "        return not out_of_bounds(*nb_coords) and garden[nb_coords] == plant_type\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= garden.shape[0] or j >= garden.shape[1]\n",
    "\n",
    "    def dfs(coords, plant_type, component):\n",
    "        component.append(coords)\n",
    "        visited[coords] = True\n",
    "        perimeter = 4\n",
    "        for delta in deltas:\n",
    "            nb_coords = add_delta(coords, delta)\n",
    "            if is_connected(nb_coords, plant_type):\n",
    "                perimeter -= 1\n",
    "                if not visited[nb_coords]:\n",
    "                    perimeter += dfs(nb_coords, plant_type, component)\n",
    "        return perimeter\n",
    "\n",
    "    price = 0\n",
    "    for coords, curr_plot in np.ndenumerate(garden):\n",
    "        if not visited[coords]:\n",
    "            connected_component = []\n",
    "            perimeter = dfs(coords, curr_plot, connected_component)\n",
    "            price += len(connected_component) * perimeter\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464678"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garden_txt = open(\"inputs/12.txt\").read()\n",
    "\n",
    "fencing_price(garden_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877492"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discounted_fencing_price(garden_txt):\n",
    "    garden = np.array(list(map(list, garden_txt.split())))\n",
    "\n",
    "    visited = np.zeros_like(garden, dtype=bool)\n",
    "    deltas = (\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (1, 0),\n",
    "        (0, -1),\n",
    "    )\n",
    "\n",
    "    def is_connected(nb_coords, plant_type):\n",
    "        return not out_of_bounds(*nb_coords) and garden[nb_coords] == plant_type\n",
    "\n",
    "    def out_of_bounds(i, j):\n",
    "        return i < 0 or j < 0 or i >= garden.shape[0] or j >= garden.shape[1]\n",
    "\n",
    "    def dfs(coords, plant_type, component):\n",
    "        component.append(coords)\n",
    "        visited[coords] = True\n",
    "\n",
    "        for delta in deltas:\n",
    "            nb_coords = add_delta(coords, delta)\n",
    "            if is_connected(nb_coords, plant_type):\n",
    "                if not visited[nb_coords]:\n",
    "                    dfs(nb_coords, plant_type, component)\n",
    "\n",
    "    price = 0\n",
    "    for coords, curr_plot in np.ndenumerate(garden):\n",
    "        if not visited[coords]:\n",
    "            connected_component = []\n",
    "            dfs(coords, curr_plot, connected_component)\n",
    "            sides = 0\n",
    "            for i, coords in enumerate(connected_component):\n",
    "                for direction in Direction:\n",
    "                    delta = deltas[direction.value]\n",
    "                    if not is_connected(add_delta(coords, delta), curr_plot):\n",
    "                        left_rotated_nb_coords = add_delta(coords, deltas[rotate_left(direction).value])\n",
    "                        if not is_connected(left_rotated_nb_coords, curr_plot) or is_connected(\n",
    "                            add_delta(left_rotated_nb_coords, delta), curr_plot\n",
    "                        ):\n",
    "                            sides += 1\n",
    "\n",
    "            price += len(connected_component) * sides\n",
    "    return price\n",
    "\n",
    "\n",
    "discounted_fencing_price(garden_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(37686)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_machine_input(line):\n",
    "    return re.findall(r\"Button A: X\\+([0-9]+), Y\\+([0-9]+)\\nButton B: X\\+([0-9]+), Y\\+([0-9]+)\\nPrize: X=([0-9]+), Y=([0-9]+)\", line)[\n",
    "        0\n",
    "    ]\n",
    "\n",
    "\n",
    "def min_tokens(machine_input_line, fix_unit_conversion=False):\n",
    "    x_a, y_a, x_b, y_b, price_x, price_y = map(int, process_machine_input(machine_input_line))\n",
    "    A = np.array(\n",
    "        [\n",
    "            [x_a, x_b],\n",
    "            [y_a, y_b],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    assert np.linalg.det(A) != 0\n",
    "\n",
    "    p = np.array([price_x, price_y])\n",
    "    if fix_unit_conversion:\n",
    "        p += 10000000000000\n",
    "\n",
    "    n_tokens = np.linalg.solve(A, p).round().astype(int)\n",
    "\n",
    "    if not np.array_equal(A @ n_tokens, p):\n",
    "        return 0\n",
    "\n",
    "    return 3 * n_tokens[0] + n_tokens[1]\n",
    "\n",
    "\n",
    "machine_inputs_txt = open(\"inputs/13.txt\").read()[:-1].split(\"\\n\\n\")\n",
    "sum(map(min_tokens, machine_inputs_txt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(77204516023437)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(min_tokens(line, fix_unit_conversion=True) for line in machine_inputs_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_inputs_txt = open(\"inputs/14.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209409792"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safety_factor(robot_inputs_txt, bathroom_shape, n_seconds=100):\n",
    "    bathroom_shape = np.array(bathroom_shape)\n",
    "    positions, velocities = np.split(\n",
    "        np.array(re.findall(r\"p=([0-9]+),([0-9]+) v=(-?[0-9]+),(-?[0-9]+)\", robot_inputs_txt), dtype=int),\n",
    "        2,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    new_positions = (positions + velocities * n_seconds) % bathroom_shape\n",
    "    split_lines = bathroom_shape // 2\n",
    "\n",
    "    ans = 1\n",
    "    for in_quadrant in [\n",
    "        (new_positions[:, 0] < split_lines[0]) & (new_positions[:, 1] < split_lines[1]),\n",
    "        (new_positions[:, 0] < split_lines[0]) & (new_positions[:, 1] > split_lines[1]),\n",
    "        (new_positions[:, 0] > split_lines[0]) & (new_positions[:, 1] < split_lines[1]),\n",
    "        (new_positions[:, 0] > split_lines[0]) & (new_positions[:, 1] > split_lines[1]),\n",
    "    ]:\n",
    "        ans *= np.count_nonzero(in_quadrant)\n",
    "    return ans\n",
    "\n",
    "\n",
    "safety_factor(robot_inputs_txt, (101, 103))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8006"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def largest_component(positions, bathroom_shape):\n",
    "    grid = np.zeros(bathroom_shape, int)\n",
    "    np.add.at(grid, (positions[:, 0], positions[:, 1]), 1)\n",
    "\n",
    "    assert np.sum(grid) == len(positions)\n",
    "    visited = np.zeros(grid.shape, bool)\n",
    "\n",
    "    def dfs(coords, n_robots):\n",
    "        if visited[coords]:\n",
    "            return n_robots\n",
    "        visited[coords] = True\n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                if dx == 0 and dy == 0:\n",
    "                    continue\n",
    "\n",
    "                x_next = coords[0] + dx\n",
    "                y_next = coords[1] + dy\n",
    "                if x_next < 0 or y_next < 0 or x_next >= bathroom_shape[0] or y_next >= bathroom_shape[1]:\n",
    "                    continue\n",
    "                if grid[x_next, y_next] > 0:\n",
    "                    n_robots = dfs((x_next, y_next), n_robots)\n",
    "        return n_robots + 1\n",
    "\n",
    "    return max(dfs((x, y), 0) for x, y in positions)\n",
    "\n",
    "\n",
    "def christmas_tree_time(robot_inputs_txt, bathroom_shape, t_max=100, verbose=False):\n",
    "    bathroom_shape = np.array(bathroom_shape)\n",
    "    positions, velocities = np.split(\n",
    "        np.array(re.findall(r\"p=([0-9]+),([0-9]+) v=(-?[0-9]+),(-?[0-9]+)\", robot_inputs_txt), dtype=int),\n",
    "        2,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    best_so_far = 1\n",
    "    for t in range(1, t_max + 1):\n",
    "        positions = (positions + velocities) % bathroom_shape\n",
    "        conn = largest_component(positions, bathroom_shape)\n",
    "        if conn > best_so_far:\n",
    "            if conn > positions.shape[0] * 0.1:\n",
    "                if verbose:\n",
    "                    grid = np.zeros(bathroom_shape, int)\n",
    "                    np.add.at(grid, (positions[:, 0], positions[:, 1]), 1)\n",
    "                    for line in grid.T:\n",
    "                        print(\"\".join([str(val) if val > 0 else \" \" for val in line]))\n",
    "                return t\n",
    "            best_so_far = conn\n",
    "    return -1\n",
    "\n",
    "\n",
    "christmas_tree_time(robot_inputs_txt, (101, 103), t_max=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
