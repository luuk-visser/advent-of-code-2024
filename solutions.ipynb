{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(number):\n",
    "  return np.loadtxt(f\"inputs/{number}.txt\", dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2000468)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_input(1)\n",
    "sorted_data = np.sort(data, axis=0)\n",
    "np.abs(sorted_data[:, 0] - sorted_data[:, 1]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18567089.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.concat(\n",
    "  [\n",
    "    pd.Series(sorted_data[:, 0]).value_counts().rename(\"0\"),\n",
    "    pd.Series(sorted_data[:, 1]).value_counts().rename(\"1\"),\n",
    "  ],\n",
    "  axis=1,\n",
    ").dropna()\n",
    "\n",
    "(counts.iloc[:, 0] * counts.iloc[:, 1] * counts.index).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = [np.fromiter(line.split(), int) for line in open('inputs/2.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(502)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_safe(report):\n",
    "  changes = np.diff(report)\n",
    "  signs = np.sign(changes)\n",
    "  return signs[0] != 0 and (signs == signs[0]).all() and (np.abs(changes) <= 3).all()\n",
    "\n",
    "sum(map(is_safe, reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def are_valid_changes(changes, possible_sign):\n",
    "  return (np.sign(changes) == possible_sign) & (np.abs(changes) <= 3)\n",
    "\n",
    "def is_safe_with_dampener(report):\n",
    "  if report.size < 3:\n",
    "    return True\n",
    "  \n",
    "  changes = np.diff(report)\n",
    "  signs = np.sign(changes)\n",
    "  for possible_sign in [-1, 1]:\n",
    "    errors = ~are_valid_changes(changes, possible_sign)\n",
    "    n_errors = errors.sum()\n",
    "    if n_errors > 2:\n",
    "      continue\n",
    "    elif n_errors == 2:\n",
    "      idcs = np.nonzero(errors)[0]\n",
    "      if idcs[0] + 1 != idcs[1] or not are_valid_changes(changes[idcs[0]] + changes[idcs[1]], possible_sign):\n",
    "        continue\n",
    "    elif n_errors == 1:\n",
    "      idx = np.argmax(errors)\n",
    "      if (\n",
    "        idx != 0 and\n",
    "        idx != changes.size - 1 and\n",
    "        not are_valid_changes(changes[idx] + changes[idx+1], possible_sign) and\n",
    "        not are_valid_changes(changes[idx-1] + changes[idx], possible_sign)\n",
    "      ):\n",
    "        continue\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "sum(map(is_safe_with_dampener, reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = open('inputs/3.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180233229"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(int(a) * int(b) for a, b in re.findall(r\"mul\\(([0-9]+),([0-9]+)\\)\", memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95411583"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_with_conditionals(memory):\n",
    "    total_sum = 0\n",
    "    enabled = True\n",
    "    for a, b, do_string, dont_string in re.findall(r\"mul\\(([0-9]+),([0-9]+)\\)|(do\\(\\))|(don't\\(\\))\", memory):\n",
    "      if a:\n",
    "        if enabled:\n",
    "          total_sum += int(a) * int(b)\n",
    "      elif do_string:\n",
    "        enabled = True\n",
    "      elif dont_string:\n",
    "        enabled = False\n",
    "    return total_sum\n",
    "\n",
    "calc_with_conditionals(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = np.array(list(map(list, open('inputs/4.txt').read().split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_xmas(text, words=(\"XMAS\", \"SAMX\")):\n",
    "  total_count = 0\n",
    "  n, m = text.shape\n",
    "  \n",
    "  for view in [\n",
    "    text, \n",
    "    text.T, \n",
    "    [np.diagonal(text, offset=offset) for offset in range(-n + 1, m)],\n",
    "    [np.diagonal(np.flipud(text), offset=offset) for offset in range(-n + 1, m)]\n",
    "  ]:\n",
    "    total_count += sum(''.join(line).count(word) for line in view for word in words)\n",
    "\n",
    "  return total_count\n",
    "\n",
    "count_xmas(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1921"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_max(text):\n",
    "  total_count = 0\n",
    "  n, m = text.shape\n",
    "  for i_min in range(n-2):\n",
    "    for j_min in range(m-2):\n",
    "      if text[i_min+1, j_min+1] == 'A':\n",
    "        i_max = i_min + 2\n",
    "        j_max = j_min + 2\n",
    "        diag_txt = text[[i_min, i_min, i_max, i_max], [j_min, j_max, j_min, j_max]]\n",
    "        if diag_txt[0] != diag_txt[3] and np.count_nonzero(diag_txt == 'S') == 2 and np.count_nonzero(diag_txt == 'M') == 2:\n",
    "          total_count += 1\n",
    "  return total_count\n",
    "\n",
    "count_max(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_txt, updates_txt = open('inputs/5.txt').read().split(\"\\n\\n\")\n",
    "rules = [(int(x), int(y)) for x, y in (rule.split(\"|\") for rule in rules_txt.split())]\n",
    "updates = [[int(x) for x in line.split(',')] for line in updates_txt.split()]\n",
    "succeeding_pages = defaultdict(set)\n",
    "for rule in rules:\n",
    "  succeeding_pages[rule[0]].add(rule[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6384\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "def is_correctly_ordered(update):\n",
    "  return not any(x in succeeding_pages[y] for x, y in combinations(update, 2))\n",
    "\n",
    "def middle_page(update):\n",
    "  return update[(len(update) - 1) // 2]\n",
    "\n",
    "total_sum = sum(middle_page(update) for update in updates if is_correctly_ordered(update))\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5353"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "def fix_update(update):\n",
    "  update = copy(update)\n",
    "  for i, _ in enumerate(update):\n",
    "    j = i+1\n",
    "    while j < len(update):\n",
    "      if update[i] in succeeding_pages[update[j]]:\n",
    "        update[i], update[j] = update[j], update[i]\n",
    "        j = i + 1\n",
    "      else:\n",
    "        j += 1\n",
    "  return update\n",
    "\n",
    "incorrect_updates = (update for update in updates if not is_correctly_ordered(update))\n",
    "sum(middle_page(fix_update(update)) for update in incorrect_updates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5269"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Direction(Enum):\n",
    "    UP = 0\n",
    "    RIGHT = 1\n",
    "    DOWN = 2\n",
    "    LEFT = 3\n",
    "\n",
    "dx_vectors = np.array([\n",
    "  [-1, 0],\n",
    "  [0, 1],\n",
    "  [1, 0],\n",
    "  [0, -1],\n",
    "])\n",
    "\n",
    "def get_dx(direction):\n",
    "  return dx_vectors[direction.value]\n",
    "\n",
    "def rotate_right(direction):\n",
    "    return Direction((direction.value + 1) % 4)\n",
    "\n",
    "def get_direction(symbol):\n",
    "  return Direction(\"^>V<\".index(symbol))  \n",
    "\n",
    "class Grid:\n",
    "  def __init__(self, grid_txt):\n",
    "    self.grid = np.array(list(map(list, grid_txt.split())))\n",
    "    self.n, self.m = self.grid.shape\n",
    "    self.reset_history()\n",
    "\n",
    "  def reset_history(self):\n",
    "    self.history = np.zeros((*self.grid.shape, 4), bool)\n",
    "\n",
    "  def get(self, pos):\n",
    "    return self.grid[tuple(pos)]\n",
    "  \n",
    "  def move_forward(self, pos, direction):\n",
    "    return pos + get_dx(direction)\n",
    "  \n",
    "  def next_state(self, pos, direction):\n",
    "    new_pos = self.move_forward(pos, direction)\n",
    "    if self.out_of_bounds(new_pos):\n",
    "      return new_pos, direction, True\n",
    "    if self.get(new_pos) == '#':\n",
    "      direction = rotate_right(direction)\n",
    "    else:\n",
    "      pos = new_pos\n",
    "    return pos, direction, False\n",
    "  \n",
    "  def find_guard_position(self):\n",
    "    for i in range(self.n):\n",
    "      for j in range(self.m):\n",
    "        if self.grid[i,j] != '.' and self.grid[i,j] != '#':\n",
    "          return i,j\n",
    "    return -1, -1\n",
    "    \n",
    "  def out_of_bounds(self, pos):\n",
    "    return pos[0] < 0 or pos[0] >= self.n or pos[1] < 0 or pos[1] >= self.m\n",
    "  \n",
    "  def mark_visited(self, pos, direction):\n",
    "    self.history[pos[0], pos[1], direction.value] = True\n",
    "\n",
    "  def already_visited(self, pos, direction):\n",
    "    return self.history[pos[0], pos[1], direction.value] \n",
    "\n",
    "  def count_visited(self):\n",
    "    return np.count_nonzero(self.history.any(axis=2))\n",
    "\n",
    "def distinct_positions(grid_txt):\n",
    "  grid = Grid(grid_txt)\n",
    "  pos = np.array(grid.find_guard_position())\n",
    "  direction = get_direction(grid.get(pos))\n",
    "  out_of_bounds = False\n",
    "\n",
    "  while not out_of_bounds:\n",
    "    grid.mark_visited(pos, direction)\n",
    "    pos, direction, out_of_bounds = grid.next_state(pos, direction)\n",
    "    \n",
    "  return grid.count_visited()\n",
    "  \n",
    "grid_txt = open('inputs/6.txt').read()\n",
    "distinct_positions(grid_txt) # 5269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def looping_obstacles(grid_txt):\n",
    "  n_looping_obstacles = 0\n",
    "  grid = Grid(grid_txt)\n",
    "  initial_pos = np.array(grid.find_guard_position())\n",
    "  initial_direction = get_direction(grid.get(initial_pos))     \n",
    "  \n",
    "  for i in range(grid.n):\n",
    "    for j in range(grid.m):\n",
    "      if grid.grid[i, j] != '.':\n",
    "        continue      \n",
    "      \n",
    "      grid.reset_history()\n",
    "      grid.grid[i,j] = '#'\n",
    "      pos = initial_pos\n",
    "      direction = initial_direction\n",
    "      out_of_bounds = False\n",
    "      while not out_of_bounds:\n",
    "        if grid.already_visited(pos, direction):\n",
    "          n_looping_obstacles += 1\n",
    "          break\n",
    "        grid.mark_visited(pos, direction)\n",
    "        pos, direction, out_of_bounds = grid.next_state(pos, direction)\n",
    "\n",
    "      grid.grid[i,j] = \".\"\n",
    "\n",
    "  return n_looping_obstacles\n",
    "\n",
    "looping_obstacles(grid_txt) # 1957\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equations(equations_txt):\n",
    "  return [(int(test), np.fromstring(numbers, int, sep=' ')) for test, numbers in (equation.split(': ') for equation in equations_txt.splitlines())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20281182715321"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_combinations(test, numbers, current_value=0):\n",
    "  if numbers.size == 0:\n",
    "    return test == current_value\n",
    "  if current_value > test:\n",
    "    return False\n",
    "  return (\n",
    "    check_combinations(test, numbers[1:], current_value=current_value + numbers[0]) or \n",
    "    check_combinations(test, numbers[1:], current_value=current_value * numbers[0])\n",
    "  )\n",
    "\n",
    "equations_txt = open('inputs/7.txt').read()\n",
    "equations = get_equations(equations_txt)\n",
    "\n",
    "sum(test for test, numbers in equations if check_combinations(test, numbers))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_combinations_with_concat(test, numbers, current_value=0):\n",
    "  if numbers.size == 0:\n",
    "    return test == current_value\n",
    "  if current_value > test:\n",
    "    return False\n",
    "  return (\n",
    "    check_combinations_with_concat(test, numbers[1:], current_value=current_value + numbers[0]) or \n",
    "    check_combinations_with_concat(test, numbers[1:], current_value=current_value * numbers[0]) or\n",
    "    check_combinations_with_concat(test, numbers[1:], current_value=int(str(current_value) + str(numbers[0])))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159490400628354"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test for test, numbers in equations if check_combinations_with_concat(test, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_antenna_locs(antenna_map):\n",
    "  locs = defaultdict(list)\n",
    "  for i, line in enumerate(antenna_map):\n",
    "    for j, symbol in enumerate(line):\n",
    "      if symbol != '.':\n",
    "        locs[symbol].append(np.array([i,j]))\n",
    "  return locs\n",
    "\n",
    "antenna_map_txt = open('inputs/8.txt').read()\n",
    "\n",
    "antenna_map_example_txt = \"\"\"\\\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "def within_bounds(coords, max_coords):\n",
    "  return (coords >= 0).all() and (coords < max_coords).all()\n",
    "\n",
    "def get_n_antinodes(antenna_map_txt):\n",
    "  antenna_map = antenna_map_txt.splitlines()\n",
    "  antenna_locs = get_antenna_locs(antenna_map)\n",
    "\n",
    "  antinode_locs = set()\n",
    "  max_coords = np.array([len(antenna_map), len(antenna_map[0])])\n",
    "  for freq_locs in antenna_locs.values():\n",
    "    for c1, c2 in combinations(freq_locs, 2):\n",
    "      diff = c2 - c1\n",
    "      for antinode in (c1 - diff, c2 + diff):\n",
    "        if within_bounds(antinode, max_coords):\n",
    "          antinode_locs.add(tuple(antinode))\n",
    "\n",
    "  return len(antinode_locs)\n",
    "\n",
    "get_n_antinodes(antenna_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_resonant_antinodes(antenna_map_txt):\n",
    "  antenna_map = antenna_map_txt.splitlines()\n",
    "  antenna_locs = get_antenna_locs(antenna_map)\n",
    "\n",
    "  antinode_locs = set()\n",
    "  max_coords = np.array([len(antenna_map), len(antenna_map[0])])\n",
    "\n",
    "  for freq_locs in antenna_locs.values():\n",
    "    for c1, c2 in combinations(freq_locs, 2):\n",
    "      for pos, offset in ((c1.copy(), c1-c2), (c2.copy(), c2-c1)):\n",
    "        while within_bounds(pos, max_coords):\n",
    "          antinode_locs.add(tuple(pos))\n",
    "          pos += offset\n",
    "  return len(antinode_locs)\n",
    "\n",
    "get_n_resonant_antinodes(antenna_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_map_txt = open('inputs/9.txt').read()[:-1]\n",
    "\n",
    "def position_sum(curr_pos, new_pos):\n",
    "    return (new_pos + curr_pos - 1) * (new_pos - curr_pos) // 2\n",
    "\n",
    "def update_checksum_and_position(checksum, curr_pos, digit, digit_idx):\n",
    "  new_pos = curr_pos + digit\n",
    "  checksum += digit_idx * position_sum(curr_pos, new_pos)\n",
    "  return checksum, new_pos\n",
    "\n",
    "def reordered_checksum(disk_map_txt):\n",
    "  digits = list(map(int, disk_map_txt[::2]))\n",
    "  spaces = list(map(int, disk_map_txt[1::2]))\n",
    "  checksum = 0\n",
    "  curr_pos = 0\n",
    "  end_idx = len(digits) - 1\n",
    "  for idx, _ in enumerate(digits):\n",
    "    checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, digits[idx], idx)\n",
    "\n",
    "    if end_idx <= idx:\n",
    "      break\n",
    "\n",
    "    while end_idx > idx and spaces[idx] > 0:\n",
    "      filled_positions = min(digits[end_idx], spaces[idx])\n",
    "      spaces[idx] -= filled_positions\n",
    "      digits[end_idx] -= filled_positions\n",
    "      checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, filled_positions, end_idx)\n",
    "      if digits[end_idx] == 0:\n",
    "         end_idx -= 1\n",
    "\n",
    "  return checksum\n",
    "         \n",
    "\n",
    "disk_map_example_txt = \"2333133121414131402\"\n",
    "reordered_checksum(disk_map_example_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6408966547049"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def defragmented_checksum(disk_map_txt):\n",
    "  digits_per_pos = [[(dig_id, int(symbol))] for dig_id, symbol in enumerate(disk_map_txt[::2])]\n",
    "  spaces = list(map(int, disk_map_txt[1::2])) + [0]\n",
    "\n",
    "  for end_idx, _ in reversed(list(enumerate(digits_per_pos))):\n",
    "    dig_id, digit = digits_per_pos[end_idx][0]\n",
    "    for space_idx, _ in enumerate(spaces):\n",
    "      if space_idx >= end_idx:\n",
    "        break\n",
    "      if spaces[space_idx] >= digit:\n",
    "        spaces[space_idx] -= digit\n",
    "        digits_per_pos[space_idx].append((dig_id, digit))\n",
    "        spaces[dig_id - 1] += digit\n",
    "        digits_per_pos[dig_id][0] = (dig_id, 0)\n",
    "        break\n",
    "\n",
    "  curr_pos = 0\n",
    "  checksum = 0\n",
    "  for idx, digit_list in enumerate(digits_per_pos):\n",
    "    for dig_id, digit in digit_list:\n",
    "      checksum, curr_pos = update_checksum_and_position(checksum, curr_pos, digit, dig_id)\n",
    "    curr_pos += spaces[idx]\n",
    "\n",
    "  return checksum\n",
    "\n",
    "    \n",
    "\n",
    "defragmented_checksum(disk_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_map_txt = open(\"inputs/10.txt\").read()\n",
    "topo_map_example_txt = \"\"\"\\\n",
    "89010123\n",
    "78121874\n",
    "87430965\n",
    "96549874\n",
    "45678903\n",
    "32019012\n",
    "01329801\n",
    "10456732\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_score(topo_map_txt):\n",
    "    topo_map = np.array([list(map(int, line)) for line in topo_map_txt.splitlines()])\n",
    "\n",
    "    def out_of_bounds(i,j):\n",
    "        return i < 0 or j < 0 or i >= topo_map.shape[0] or j >= topo_map.shape[1]\n",
    "    \n",
    "    deltas = np.array([\n",
    "        [0,1],\n",
    "        [1,0],\n",
    "        [0,-1],\n",
    "        [-1,0],\n",
    "    ])\n",
    "    score = 0\n",
    "    trailheads = np.argwhere(topo_map == 0)\n",
    "    for trailhead in trailheads:\n",
    "        visited = np.zeros_like(topo_map, dtype=bool)\n",
    "        stack = [trailhead]\n",
    "        while stack:\n",
    "            top = stack.pop()\n",
    "            if visited[tuple(top)]:\n",
    "                continue\n",
    "            \n",
    "            if topo_map[tuple(top)] == 9:\n",
    "                score += 1\n",
    "            visited[tuple(top)] = True\n",
    "            for delta in deltas:\n",
    "                new_pos = top + delta\n",
    "                if (\n",
    "                    not out_of_bounds(*new_pos) and \n",
    "                    not visited[tuple(new_pos)] and \n",
    "                    topo_map[tuple(new_pos)] == topo_map[tuple(top)] + 1\n",
    "                ):\n",
    "                    stack.append(new_pos)\n",
    "    return score\n",
    "            \n",
    "\n",
    "    print(trailheads)\n",
    "\n",
    "map_score(topo_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1324)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_score(topo_map_txt):\n",
    "    topo_map = np.array([list(map(int, line)) for line in topo_map_txt.splitlines()])\n",
    "\n",
    "    def out_of_bounds(i,j):\n",
    "        return i < 0 or j < 0 or i >= topo_map.shape[0] or j >= topo_map.shape[1]\n",
    "    \n",
    "    deltas = np.array([\n",
    "        [0,1],\n",
    "        [1,0],\n",
    "        [0,-1],\n",
    "        [-1,0],\n",
    "    ])\n",
    "    score = 0\n",
    "    trailheads = np.argwhere(topo_map == 0)\n",
    "    \n",
    "    visited = np.zeros_like(topo_map, dtype=int)\n",
    "    for pos in trailheads:\n",
    "        visited[tuple(pos)] = 1\n",
    "    new_stack = list(trailheads)\n",
    "    height = 0\n",
    "    \n",
    "    while new_stack:\n",
    "        stack = new_stack\n",
    "        new_stack = []\n",
    "        for pos in stack:\n",
    "            for delta in deltas:\n",
    "                new_pos = pos + delta\n",
    "                if (\n",
    "                    not out_of_bounds(*new_pos) and \n",
    "                    topo_map[tuple(new_pos)] == height + 1\n",
    "                ):\n",
    "                    if not visited[tuple(new_pos)]:\n",
    "                        new_stack.append(new_pos)\n",
    "                    visited[tuple(new_pos)] += visited[tuple(pos)]\n",
    "        height += 1\n",
    "    \n",
    "    score = sum(visited[tuple(pos)] for pos in np.argwhere(topo_map == 9))\n",
    "    return score\n",
    "\n",
    "map_score(topo_map_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
